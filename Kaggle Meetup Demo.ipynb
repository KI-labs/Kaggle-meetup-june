{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering\n",
    "## Kaggle Meetup Demo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"./data\"\n",
    "train_dataset = \"train.csv\"\n",
    "test_dataset = \"test.csv\"\n",
    "targe_column = \"SalePrice\"\n",
    "\n",
    "train_dataframe = pd.read_csv(os.path.join(data_path, train_dataset))\n",
    "test_dataframe = pd.read_csv(os.path.join(data_path, test_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Information about the dataset\n",
    "There are 1460 rows <br>\n",
    "The train dataset contains 81 columns <br>\n",
    "The test dataset contains 80 columns <br>\n",
    "There are 43 categorical columns with string labels <br>\n",
    "There are 18 categorical columns with integer labels <br>\n",
    "<b>NOTE: categorical columns that contains more than 30 classes are considered continuous numeric features</b> <br>\n",
    "NOTE: You can modify the threshold value if you are not satisfied with the results.<br>\n",
    "There are 20 numeric columns with continuous values<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical = ['LotFrontage', 'LotArea', 'YearBuilt', 'YearRemodAdd', 'MasVnrArea', 'BsmtFinSF1', 'BsmtFinSF2',\n",
    "             'BsmtUnfSF', 'TotalBsmtSF', '1stFlrSF', '2ndFlrSF', 'GrLivArea', 'GarageYrBlt', 'GarageArea',\n",
    "             'WoodDeckSF', 'OpenPorchSF', 'EnclosedPorch', 'ScreenPorch']\n",
    "\n",
    "\n",
    "# get the target and use the log transformation\n",
    "train_target = np.log(train_dataframe[targe_column])\n",
    "\n",
    "# drop the target and id columns\n",
    "train_dataframe = train_dataframe.drop([targe_column], axis=1)\n",
    "train_id = train_dataframe.Id\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1460, 80)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "def encoding_categorical_features(feature_name, dataset_list):\n",
    "    \"\"\"\n",
    "    Encoding categorical features and save the labels of the categories to folder encoding_classes_labels. It is\n",
    "    possible to use train data alone or all train data, validation data and test data. If all datesets are provided\n",
    "    (i.e. train, valid and test), they will be concatenated first and then encoded.\n",
    "    :param feature_name: string - will be used to name the file where the classes labels will be stored\n",
    "    :param dataset_list: list of pandas series (i.e one column) that must contain the train data and optionally\n",
    "     contains valid data and test data\n",
    "    :return:\n",
    "    \"\"\"\n",
    "\n",
    "    # concatenate dataset if needed\n",
    "    print(\"the are {} datasets provided\".format(len(dataset_list)))\n",
    "    valid_dataset_list = [x for x in dataset_list if x.shape[0] > 0]\n",
    "\n",
    "    if len(valid_dataset_list) > 1:\n",
    "        X_orginal = pd.concat(valid_dataset_list, axis=0)\n",
    "    else:\n",
    "        X_orginal = dataset_list[0]\n",
    "\n",
    "    train_data = dataset_list[0]\n",
    "    # define the encoder\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    le.fit(X_orginal.fillna(-999999))\n",
    "    dataset_list = []\n",
    "    for dataset_i in valid_dataset_list:\n",
    "        dataset_list.append(le.transform(dataset_i.fillna(-999999)))\n",
    "\n",
    "    lables_nr = len(list(le.classes_))\n",
    "    print(\"the number of classes in {} feature is: {}\".format(feature_name, lables_nr))\n",
    "    return dataset_list, le\n",
    "\n",
    "def standard_scale_nuermical_features(dataframe):\n",
    "    scaler = preprocessing.StandardScaler().fit(dataframe)\n",
    "\n",
    "    train_scaled = scaler.transform(dataframe)\n",
    "    train_scaled[np.isnan(train_scaled)] = 0\n",
    "    train_scaled = pd.DataFrame(train_scaled, columns=dataframe.columns)\n",
    "\n",
    "    return train_scaled\n",
    "\n",
    "train_dataframe_normalized = standard_scale_nuermical_features(train_dataframe[numerical])\n",
    "train_dataframe[numerical] = train_dataframe_normalized\n",
    "print(train_dataframe.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>YearRemodAdd</th>\n",
       "      <th>MasVnrArea</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>BsmtFinSF2</th>\n",
       "      <th>BsmtUnfSF</th>\n",
       "      <th>TotalBsmtSF</th>\n",
       "      <th>1stFlrSF</th>\n",
       "      <th>2ndFlrSF</th>\n",
       "      <th>GrLivArea</th>\n",
       "      <th>GarageYrBlt</th>\n",
       "      <th>GarageArea</th>\n",
       "      <th>WoodDeckSF</th>\n",
       "      <th>OpenPorchSF</th>\n",
       "      <th>EnclosedPorch</th>\n",
       "      <th>ScreenPorch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.460000e+03</td>\n",
       "      <td>1.460000e+03</td>\n",
       "      <td>1.460000e+03</td>\n",
       "      <td>1.460000e+03</td>\n",
       "      <td>1.460000e+03</td>\n",
       "      <td>1.460000e+03</td>\n",
       "      <td>1.460000e+03</td>\n",
       "      <td>1.460000e+03</td>\n",
       "      <td>1.460000e+03</td>\n",
       "      <td>1.460000e+03</td>\n",
       "      <td>1.460000e+03</td>\n",
       "      <td>1.460000e+03</td>\n",
       "      <td>1.460000e+03</td>\n",
       "      <td>1.460000e+03</td>\n",
       "      <td>1.460000e+03</td>\n",
       "      <td>1.460000e+03</td>\n",
       "      <td>1.460000e+03</td>\n",
       "      <td>1.460000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-2.341924e-16</td>\n",
       "      <td>-4.202783e-17</td>\n",
       "      <td>1.032983e-15</td>\n",
       "      <td>4.518912e-15</td>\n",
       "      <td>2.547430e-16</td>\n",
       "      <td>1.505645e-17</td>\n",
       "      <td>1.653168e-16</td>\n",
       "      <td>-7.376139e-17</td>\n",
       "      <td>2.063038e-16</td>\n",
       "      <td>7.686013e-17</td>\n",
       "      <td>-3.269835e-17</td>\n",
       "      <td>-1.446332e-16</td>\n",
       "      <td>3.844565e-15</td>\n",
       "      <td>-2.022735e-17</td>\n",
       "      <td>2.190029e-16</td>\n",
       "      <td>3.357284e-17</td>\n",
       "      <td>1.379034e-16</td>\n",
       "      <td>1.199193e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>9.072853e-01</td>\n",
       "      <td>1.000343e+00</td>\n",
       "      <td>1.000343e+00</td>\n",
       "      <td>1.000343e+00</td>\n",
       "      <td>9.975982e-01</td>\n",
       "      <td>1.000343e+00</td>\n",
       "      <td>1.000343e+00</td>\n",
       "      <td>1.000343e+00</td>\n",
       "      <td>1.000343e+00</td>\n",
       "      <td>1.000343e+00</td>\n",
       "      <td>1.000343e+00</td>\n",
       "      <td>1.000343e+00</td>\n",
       "      <td>9.721975e-01</td>\n",
       "      <td>1.000343e+00</td>\n",
       "      <td>1.000343e+00</td>\n",
       "      <td>1.000343e+00</td>\n",
       "      <td>1.000343e+00</td>\n",
       "      <td>1.000343e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-2.020626e+00</td>\n",
       "      <td>-9.237292e-01</td>\n",
       "      <td>-3.287824e+00</td>\n",
       "      <td>-1.689368e+00</td>\n",
       "      <td>-5.728346e-01</td>\n",
       "      <td>-9.730182e-01</td>\n",
       "      <td>-2.886528e-01</td>\n",
       "      <td>-1.284176e+00</td>\n",
       "      <td>-2.411167e+00</td>\n",
       "      <td>-2.144172e+00</td>\n",
       "      <td>-7.951632e-01</td>\n",
       "      <td>-2.249120e+00</td>\n",
       "      <td>-3.180863e+00</td>\n",
       "      <td>-2.212963e+00</td>\n",
       "      <td>-7.521758e-01</td>\n",
       "      <td>-7.044833e-01</td>\n",
       "      <td>-3.593249e-01</td>\n",
       "      <td>-2.702084e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-4.140106e-01</td>\n",
       "      <td>-2.969908e-01</td>\n",
       "      <td>-5.719226e-01</td>\n",
       "      <td>-8.656586e-01</td>\n",
       "      <td>-5.728346e-01</td>\n",
       "      <td>-9.730182e-01</td>\n",
       "      <td>-2.886528e-01</td>\n",
       "      <td>-7.793259e-01</td>\n",
       "      <td>-5.966855e-01</td>\n",
       "      <td>-7.261556e-01</td>\n",
       "      <td>-7.951632e-01</td>\n",
       "      <td>-7.347485e-01</td>\n",
       "      <td>-6.687864e-01</td>\n",
       "      <td>-6.479160e-01</td>\n",
       "      <td>-7.521758e-01</td>\n",
       "      <td>-7.044833e-01</td>\n",
       "      <td>-3.593249e-01</td>\n",
       "      <td>-2.702084e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-1.040633e-01</td>\n",
       "      <td>5.737148e-02</td>\n",
       "      <td>4.425864e-01</td>\n",
       "      <td>-5.728346e-01</td>\n",
       "      <td>-1.319022e-01</td>\n",
       "      <td>-2.886528e-01</td>\n",
       "      <td>-2.031633e-01</td>\n",
       "      <td>-1.503334e-01</td>\n",
       "      <td>-1.956933e-01</td>\n",
       "      <td>-7.951632e-01</td>\n",
       "      <td>-9.797004e-02</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>3.284429e-02</td>\n",
       "      <td>-7.521758e-01</td>\n",
       "      <td>-3.270298e-01</td>\n",
       "      <td>-3.593249e-01</td>\n",
       "      <td>-2.702084e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.686993e-01</td>\n",
       "      <td>1.087080e-01</td>\n",
       "      <td>9.516316e-01</td>\n",
       "      <td>9.271216e-01</td>\n",
       "      <td>3.346047e-01</td>\n",
       "      <td>5.891327e-01</td>\n",
       "      <td>-2.886528e-01</td>\n",
       "      <td>5.450557e-01</td>\n",
       "      <td>5.491227e-01</td>\n",
       "      <td>5.915905e-01</td>\n",
       "      <td>8.731117e-01</td>\n",
       "      <td>4.974036e-01</td>\n",
       "      <td>9.113911e-01</td>\n",
       "      <td>4.820057e-01</td>\n",
       "      <td>5.886506e-01</td>\n",
       "      <td>3.221901e-01</td>\n",
       "      <td>-3.593249e-01</td>\n",
       "      <td>-2.702084e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000839e+01</td>\n",
       "      <td>2.051827e+01</td>\n",
       "      <td>1.282839e+00</td>\n",
       "      <td>1.217843e+00</td>\n",
       "      <td>8.266757e+00</td>\n",
       "      <td>1.140575e+01</td>\n",
       "      <td>8.851638e+00</td>\n",
       "      <td>4.004295e+00</td>\n",
       "      <td>1.152095e+01</td>\n",
       "      <td>9.132681e+00</td>\n",
       "      <td>3.936963e+00</td>\n",
       "      <td>7.855574e+00</td>\n",
       "      <td>1.276047e+00</td>\n",
       "      <td>4.421526e+00</td>\n",
       "      <td>6.087635e+00</td>\n",
       "      <td>7.554198e+00</td>\n",
       "      <td>8.675309e+00</td>\n",
       "      <td>8.341462e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        LotFrontage       LotArea     YearBuilt  YearRemodAdd    MasVnrArea  \\\n",
       "count  1.460000e+03  1.460000e+03  1.460000e+03  1.460000e+03  1.460000e+03   \n",
       "mean  -2.341924e-16 -4.202783e-17  1.032983e-15  4.518912e-15  2.547430e-16   \n",
       "std    9.072853e-01  1.000343e+00  1.000343e+00  1.000343e+00  9.975982e-01   \n",
       "min   -2.020626e+00 -9.237292e-01 -3.287824e+00 -1.689368e+00 -5.728346e-01   \n",
       "25%   -4.140106e-01 -2.969908e-01 -5.719226e-01 -8.656586e-01 -5.728346e-01   \n",
       "50%    0.000000e+00 -1.040633e-01  5.737148e-02  4.425864e-01 -5.728346e-01   \n",
       "75%    3.686993e-01  1.087080e-01  9.516316e-01  9.271216e-01  3.346047e-01   \n",
       "max    1.000839e+01  2.051827e+01  1.282839e+00  1.217843e+00  8.266757e+00   \n",
       "\n",
       "         BsmtFinSF1    BsmtFinSF2     BsmtUnfSF   TotalBsmtSF      1stFlrSF  \\\n",
       "count  1.460000e+03  1.460000e+03  1.460000e+03  1.460000e+03  1.460000e+03   \n",
       "mean   1.505645e-17  1.653168e-16 -7.376139e-17  2.063038e-16  7.686013e-17   \n",
       "std    1.000343e+00  1.000343e+00  1.000343e+00  1.000343e+00  1.000343e+00   \n",
       "min   -9.730182e-01 -2.886528e-01 -1.284176e+00 -2.411167e+00 -2.144172e+00   \n",
       "25%   -9.730182e-01 -2.886528e-01 -7.793259e-01 -5.966855e-01 -7.261556e-01   \n",
       "50%   -1.319022e-01 -2.886528e-01 -2.031633e-01 -1.503334e-01 -1.956933e-01   \n",
       "75%    5.891327e-01 -2.886528e-01  5.450557e-01  5.491227e-01  5.915905e-01   \n",
       "max    1.140575e+01  8.851638e+00  4.004295e+00  1.152095e+01  9.132681e+00   \n",
       "\n",
       "           2ndFlrSF     GrLivArea   GarageYrBlt    GarageArea    WoodDeckSF  \\\n",
       "count  1.460000e+03  1.460000e+03  1.460000e+03  1.460000e+03  1.460000e+03   \n",
       "mean  -3.269835e-17 -1.446332e-16  3.844565e-15 -2.022735e-17  2.190029e-16   \n",
       "std    1.000343e+00  1.000343e+00  9.721975e-01  1.000343e+00  1.000343e+00   \n",
       "min   -7.951632e-01 -2.249120e+00 -3.180863e+00 -2.212963e+00 -7.521758e-01   \n",
       "25%   -7.951632e-01 -7.347485e-01 -6.687864e-01 -6.479160e-01 -7.521758e-01   \n",
       "50%   -7.951632e-01 -9.797004e-02  0.000000e+00  3.284429e-02 -7.521758e-01   \n",
       "75%    8.731117e-01  4.974036e-01  9.113911e-01  4.820057e-01  5.886506e-01   \n",
       "max    3.936963e+00  7.855574e+00  1.276047e+00  4.421526e+00  6.087635e+00   \n",
       "\n",
       "        OpenPorchSF  EnclosedPorch   ScreenPorch  \n",
       "count  1.460000e+03   1.460000e+03  1.460000e+03  \n",
       "mean   3.357284e-17   1.379034e-16  1.199193e-16  \n",
       "std    1.000343e+00   1.000343e+00  1.000343e+00  \n",
       "min   -7.044833e-01  -3.593249e-01 -2.702084e-01  \n",
       "25%   -7.044833e-01  -3.593249e-01 -2.702084e-01  \n",
       "50%   -3.270298e-01  -3.593249e-01 -2.702084e-01  \n",
       "75%    3.221901e-01  -3.593249e-01 -2.702084e-01  \n",
       "max    7.554198e+00   8.675309e+00  8.341462e+00  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataframe[numerical].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Featuretool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=featuretool.png>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import featuretools as ft"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### how does it work?\n",
    "Generating fake data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "integer_array = np.random.randint(5, size=(100, 1))\n",
    "integer_columns = [f\"int_col_{x}\" for x in range(integer_array.shape[1])]\n",
    "continuous_array = np.random.randn(100, 5)\n",
    "continuous_columns = [f\"cont_col_{x}\" for x in range(continuous_array.shape[1])]\n",
    "\n",
    "integer_dataframe = pd.DataFrame(integer_array, columns=integer_columns)\n",
    "continuous_dataframe = pd.DataFrame(continuous_array, columns=continuous_columns)\n",
    "\n",
    "total_dataframe = pd.concat([continuous_dataframe, integer_dataframe], axis=1)\n",
    "total_dataframe[\"Id\"] = range(total_dataframe.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   cont_col_0  cont_col_1  cont_col_2  cont_col_3  cont_col_4  int_col_0  Id\n",
      "0    1.406992   -1.625066   -0.545548    0.109943    0.025338          2   0\n",
      "1    1.529180   -0.524555    0.148821    0.356770    0.060462          0   1\n",
      "2    0.650563   -2.319488   -1.010928    0.152293    0.303889          0   2\n",
      "3   -1.630199   -0.130310    0.059638   -0.847878    1.515433          1   3\n",
      "4   -0.361344   -1.443168    0.104868   -3.305410    0.581889          2   4\n"
     ]
    }
   ],
   "source": [
    "print(total_dataframe.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. We create entityset (set of dataframes)\n",
    "2. We use table Normalizing to create a new table\n",
    "3. We apply deep feature synthesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def automated_feature_extraction(dataframe_train, aggregate_features, max_depth):\n",
    "    \"\"\"\n",
    "\n",
    "    :param dataframe_train: Pandas dataframe\n",
    "    :param aggregate_features: list of strings - the categorical features that we use to apply premitives for generating\n",
    "    new features\n",
    "    :param max_depth: integer\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    es = ft.EntitySet(id=\"Id\")\n",
    "    es = es.entity_from_dataframe(entity_id=\"dataframe_train\",\n",
    "                                  dataframe=dataframe_train, index=\"Id\")\n",
    "    \n",
    "    for categ_i in aggregate_features:\n",
    "        es.normalize_entity(base_entity_id='dataframe_train', new_entity_id=f'feature_{categ_i}',\n",
    "                            index=categ_i)\n",
    "    \n",
    "    feature_matrix_train, _ = ft.dfs(entityset=es, target_entity='dataframe_train', max_depth=max_depth)\n",
    "    \n",
    "    return feature_matrix_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### new feauture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 37)\n"
     ]
    }
   ],
   "source": [
    "new_total_dataframe = automated_feature_extraction(total_dataframe, [\"int_col_0\"], max_depth=2)\n",
    "print(new_total_dataframe.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['feature_int_col_0.MAX(dataframe_train.cont_col_4)',\n",
       "       'feature_int_col_0.SKEW(dataframe_train.cont_col_0)',\n",
       "       'feature_int_col_0.SKEW(dataframe_train.cont_col_1)',\n",
       "       'feature_int_col_0.SKEW(dataframe_train.cont_col_2)',\n",
       "       'feature_int_col_0.SKEW(dataframe_train.cont_col_3)',\n",
       "       'feature_int_col_0.SKEW(dataframe_train.cont_col_4)',\n",
       "       'feature_int_col_0.MIN(dataframe_train.cont_col_0)',\n",
       "       'feature_int_col_0.MIN(dataframe_train.cont_col_1)',\n",
       "       'feature_int_col_0.MIN(dataframe_train.cont_col_2)',\n",
       "       'feature_int_col_0.MIN(dataframe_train.cont_col_3)',\n",
       "       'feature_int_col_0.MIN(dataframe_train.cont_col_4)',\n",
       "       'feature_int_col_0.MEAN(dataframe_train.cont_col_0)',\n",
       "       'feature_int_col_0.MEAN(dataframe_train.cont_col_1)',\n",
       "       'feature_int_col_0.MEAN(dataframe_train.cont_col_2)',\n",
       "       'feature_int_col_0.MEAN(dataframe_train.cont_col_3)',\n",
       "       'feature_int_col_0.MEAN(dataframe_train.cont_col_4)',\n",
       "       'feature_int_col_0.COUNT(dataframe_train)'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_total_dataframe.columns[20:40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the are 1 datasets provided\n",
      "the number of classes in MSSubClass feature is: 15\n",
      "Index(['feature_MSSubClass.MIN(dataframe_train.1stFlrSF)',\n",
      "       'feature_MSSubClass.MIN(dataframe_train.2ndFlrSF)',\n",
      "       'feature_MSSubClass.MIN(dataframe_train.GrLivArea)',\n",
      "       'feature_MSSubClass.MIN(dataframe_train.GarageYrBlt)',\n",
      "       'feature_MSSubClass.MIN(dataframe_train.GarageArea)',\n",
      "       'feature_MSSubClass.MIN(dataframe_train.WoodDeckSF)',\n",
      "       'feature_MSSubClass.MIN(dataframe_train.OpenPorchSF)',\n",
      "       'feature_MSSubClass.MIN(dataframe_train.EnclosedPorch)',\n",
      "       'feature_MSSubClass.MIN(dataframe_train.ScreenPorch)',\n",
      "       'feature_MSSubClass.MEAN(dataframe_train.LotFrontage)',\n",
      "       'feature_MSSubClass.MEAN(dataframe_train.LotArea)',\n",
      "       'feature_MSSubClass.MEAN(dataframe_train.YearBuilt)',\n",
      "       'feature_MSSubClass.MEAN(dataframe_train.YearRemodAdd)',\n",
      "       'feature_MSSubClass.MEAN(dataframe_train.MasVnrArea)',\n",
      "       'feature_MSSubClass.MEAN(dataframe_train.BsmtFinSF1)',\n",
      "       'feature_MSSubClass.MEAN(dataframe_train.BsmtFinSF2)',\n",
      "       'feature_MSSubClass.MEAN(dataframe_train.BsmtUnfSF)',\n",
      "       'feature_MSSubClass.MEAN(dataframe_train.TotalBsmtSF)',\n",
      "       'feature_MSSubClass.MEAN(dataframe_train.1stFlrSF)',\n",
      "       'feature_MSSubClass.MEAN(dataframe_train.2ndFlrSF)'],\n",
      "      dtype='object')\n",
      "the are 1 datasets provided\n",
      "the number of classes in OverallQual feature is: 10\n",
      "Index(['feature_OverallQual.MIN(dataframe_train.1stFlrSF)',\n",
      "       'feature_OverallQual.MIN(dataframe_train.2ndFlrSF)',\n",
      "       'feature_OverallQual.MIN(dataframe_train.GrLivArea)',\n",
      "       'feature_OverallQual.MIN(dataframe_train.GarageYrBlt)',\n",
      "       'feature_OverallQual.MIN(dataframe_train.GarageArea)',\n",
      "       'feature_OverallQual.MIN(dataframe_train.WoodDeckSF)',\n",
      "       'feature_OverallQual.MIN(dataframe_train.OpenPorchSF)',\n",
      "       'feature_OverallQual.MIN(dataframe_train.EnclosedPorch)',\n",
      "       'feature_OverallQual.MIN(dataframe_train.ScreenPorch)',\n",
      "       'feature_OverallQual.MEAN(dataframe_train.LotFrontage)',\n",
      "       'feature_OverallQual.MEAN(dataframe_train.LotArea)',\n",
      "       'feature_OverallQual.MEAN(dataframe_train.YearBuilt)',\n",
      "       'feature_OverallQual.MEAN(dataframe_train.YearRemodAdd)',\n",
      "       'feature_OverallQual.MEAN(dataframe_train.MasVnrArea)',\n",
      "       'feature_OverallQual.MEAN(dataframe_train.BsmtFinSF1)',\n",
      "       'feature_OverallQual.MEAN(dataframe_train.BsmtFinSF2)',\n",
      "       'feature_OverallQual.MEAN(dataframe_train.BsmtUnfSF)',\n",
      "       'feature_OverallQual.MEAN(dataframe_train.TotalBsmtSF)',\n",
      "       'feature_OverallQual.MEAN(dataframe_train.1stFlrSF)',\n",
      "       'feature_OverallQual.MEAN(dataframe_train.2ndFlrSF)'],\n",
      "      dtype='object')\n",
      "the are 1 datasets provided\n",
      "the number of classes in OverallCond feature is: 9\n",
      "Index(['feature_OverallCond.MIN(dataframe_train.1stFlrSF)',\n",
      "       'feature_OverallCond.MIN(dataframe_train.2ndFlrSF)',\n",
      "       'feature_OverallCond.MIN(dataframe_train.GrLivArea)',\n",
      "       'feature_OverallCond.MIN(dataframe_train.GarageYrBlt)',\n",
      "       'feature_OverallCond.MIN(dataframe_train.GarageArea)',\n",
      "       'feature_OverallCond.MIN(dataframe_train.WoodDeckSF)',\n",
      "       'feature_OverallCond.MIN(dataframe_train.OpenPorchSF)',\n",
      "       'feature_OverallCond.MIN(dataframe_train.EnclosedPorch)',\n",
      "       'feature_OverallCond.MIN(dataframe_train.ScreenPorch)',\n",
      "       'feature_OverallCond.MEAN(dataframe_train.LotFrontage)',\n",
      "       'feature_OverallCond.MEAN(dataframe_train.LotArea)',\n",
      "       'feature_OverallCond.MEAN(dataframe_train.YearBuilt)',\n",
      "       'feature_OverallCond.MEAN(dataframe_train.YearRemodAdd)',\n",
      "       'feature_OverallCond.MEAN(dataframe_train.MasVnrArea)',\n",
      "       'feature_OverallCond.MEAN(dataframe_train.BsmtFinSF1)',\n",
      "       'feature_OverallCond.MEAN(dataframe_train.BsmtFinSF2)',\n",
      "       'feature_OverallCond.MEAN(dataframe_train.BsmtUnfSF)',\n",
      "       'feature_OverallCond.MEAN(dataframe_train.TotalBsmtSF)',\n",
      "       'feature_OverallCond.MEAN(dataframe_train.1stFlrSF)',\n",
      "       'feature_OverallCond.MEAN(dataframe_train.2ndFlrSF)'],\n",
      "      dtype='object')\n",
      "the are 1 datasets provided\n",
      "the number of classes in LowQualFinSF feature is: 24\n",
      "Index(['feature_LowQualFinSF.MIN(dataframe_train.1stFlrSF)',\n",
      "       'feature_LowQualFinSF.MIN(dataframe_train.2ndFlrSF)',\n",
      "       'feature_LowQualFinSF.MIN(dataframe_train.GrLivArea)',\n",
      "       'feature_LowQualFinSF.MIN(dataframe_train.GarageYrBlt)',\n",
      "       'feature_LowQualFinSF.MIN(dataframe_train.GarageArea)',\n",
      "       'feature_LowQualFinSF.MIN(dataframe_train.WoodDeckSF)',\n",
      "       'feature_LowQualFinSF.MIN(dataframe_train.OpenPorchSF)',\n",
      "       'feature_LowQualFinSF.MIN(dataframe_train.EnclosedPorch)',\n",
      "       'feature_LowQualFinSF.MIN(dataframe_train.ScreenPorch)',\n",
      "       'feature_LowQualFinSF.MEAN(dataframe_train.LotFrontage)',\n",
      "       'feature_LowQualFinSF.MEAN(dataframe_train.LotArea)',\n",
      "       'feature_LowQualFinSF.MEAN(dataframe_train.YearBuilt)',\n",
      "       'feature_LowQualFinSF.MEAN(dataframe_train.YearRemodAdd)',\n",
      "       'feature_LowQualFinSF.MEAN(dataframe_train.MasVnrArea)',\n",
      "       'feature_LowQualFinSF.MEAN(dataframe_train.BsmtFinSF1)',\n",
      "       'feature_LowQualFinSF.MEAN(dataframe_train.BsmtFinSF2)',\n",
      "       'feature_LowQualFinSF.MEAN(dataframe_train.BsmtUnfSF)',\n",
      "       'feature_LowQualFinSF.MEAN(dataframe_train.TotalBsmtSF)',\n",
      "       'feature_LowQualFinSF.MEAN(dataframe_train.1stFlrSF)',\n",
      "       'feature_LowQualFinSF.MEAN(dataframe_train.2ndFlrSF)'],\n",
      "      dtype='object')\n",
      "the are 1 datasets provided\n",
      "the number of classes in BsmtFullBath feature is: 4\n",
      "Index(['feature_BsmtFullBath.MIN(dataframe_train.1stFlrSF)',\n",
      "       'feature_BsmtFullBath.MIN(dataframe_train.2ndFlrSF)',\n",
      "       'feature_BsmtFullBath.MIN(dataframe_train.GrLivArea)',\n",
      "       'feature_BsmtFullBath.MIN(dataframe_train.GarageYrBlt)',\n",
      "       'feature_BsmtFullBath.MIN(dataframe_train.GarageArea)',\n",
      "       'feature_BsmtFullBath.MIN(dataframe_train.WoodDeckSF)',\n",
      "       'feature_BsmtFullBath.MIN(dataframe_train.OpenPorchSF)',\n",
      "       'feature_BsmtFullBath.MIN(dataframe_train.EnclosedPorch)',\n",
      "       'feature_BsmtFullBath.MIN(dataframe_train.ScreenPorch)',\n",
      "       'feature_BsmtFullBath.MEAN(dataframe_train.LotFrontage)',\n",
      "       'feature_BsmtFullBath.MEAN(dataframe_train.LotArea)',\n",
      "       'feature_BsmtFullBath.MEAN(dataframe_train.YearBuilt)',\n",
      "       'feature_BsmtFullBath.MEAN(dataframe_train.YearRemodAdd)',\n",
      "       'feature_BsmtFullBath.MEAN(dataframe_train.MasVnrArea)',\n",
      "       'feature_BsmtFullBath.MEAN(dataframe_train.BsmtFinSF1)',\n",
      "       'feature_BsmtFullBath.MEAN(dataframe_train.BsmtFinSF2)',\n",
      "       'feature_BsmtFullBath.MEAN(dataframe_train.BsmtUnfSF)',\n",
      "       'feature_BsmtFullBath.MEAN(dataframe_train.TotalBsmtSF)',\n",
      "       'feature_BsmtFullBath.MEAN(dataframe_train.1stFlrSF)',\n",
      "       'feature_BsmtFullBath.MEAN(dataframe_train.2ndFlrSF)'],\n",
      "      dtype='object')\n",
      "the are 1 datasets provided\n",
      "the number of classes in BsmtHalfBath feature is: 3\n",
      "Index(['feature_BsmtHalfBath.MIN(dataframe_train.1stFlrSF)',\n",
      "       'feature_BsmtHalfBath.MIN(dataframe_train.2ndFlrSF)',\n",
      "       'feature_BsmtHalfBath.MIN(dataframe_train.GrLivArea)',\n",
      "       'feature_BsmtHalfBath.MIN(dataframe_train.GarageYrBlt)',\n",
      "       'feature_BsmtHalfBath.MIN(dataframe_train.GarageArea)',\n",
      "       'feature_BsmtHalfBath.MIN(dataframe_train.WoodDeckSF)',\n",
      "       'feature_BsmtHalfBath.MIN(dataframe_train.OpenPorchSF)',\n",
      "       'feature_BsmtHalfBath.MIN(dataframe_train.EnclosedPorch)',\n",
      "       'feature_BsmtHalfBath.MIN(dataframe_train.ScreenPorch)',\n",
      "       'feature_BsmtHalfBath.MEAN(dataframe_train.LotFrontage)',\n",
      "       'feature_BsmtHalfBath.MEAN(dataframe_train.LotArea)',\n",
      "       'feature_BsmtHalfBath.MEAN(dataframe_train.YearBuilt)',\n",
      "       'feature_BsmtHalfBath.MEAN(dataframe_train.YearRemodAdd)',\n",
      "       'feature_BsmtHalfBath.MEAN(dataframe_train.MasVnrArea)',\n",
      "       'feature_BsmtHalfBath.MEAN(dataframe_train.BsmtFinSF1)',\n",
      "       'feature_BsmtHalfBath.MEAN(dataframe_train.BsmtFinSF2)',\n",
      "       'feature_BsmtHalfBath.MEAN(dataframe_train.BsmtUnfSF)',\n",
      "       'feature_BsmtHalfBath.MEAN(dataframe_train.TotalBsmtSF)',\n",
      "       'feature_BsmtHalfBath.MEAN(dataframe_train.1stFlrSF)',\n",
      "       'feature_BsmtHalfBath.MEAN(dataframe_train.2ndFlrSF)'],\n",
      "      dtype='object')\n",
      "the are 1 datasets provided\n",
      "the number of classes in FullBath feature is: 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['feature_FullBath.MIN(dataframe_train.1stFlrSF)',\n",
      "       'feature_FullBath.MIN(dataframe_train.2ndFlrSF)',\n",
      "       'feature_FullBath.MIN(dataframe_train.GrLivArea)',\n",
      "       'feature_FullBath.MIN(dataframe_train.GarageYrBlt)',\n",
      "       'feature_FullBath.MIN(dataframe_train.GarageArea)',\n",
      "       'feature_FullBath.MIN(dataframe_train.WoodDeckSF)',\n",
      "       'feature_FullBath.MIN(dataframe_train.OpenPorchSF)',\n",
      "       'feature_FullBath.MIN(dataframe_train.EnclosedPorch)',\n",
      "       'feature_FullBath.MIN(dataframe_train.ScreenPorch)',\n",
      "       'feature_FullBath.MEAN(dataframe_train.LotFrontage)',\n",
      "       'feature_FullBath.MEAN(dataframe_train.LotArea)',\n",
      "       'feature_FullBath.MEAN(dataframe_train.YearBuilt)',\n",
      "       'feature_FullBath.MEAN(dataframe_train.YearRemodAdd)',\n",
      "       'feature_FullBath.MEAN(dataframe_train.MasVnrArea)',\n",
      "       'feature_FullBath.MEAN(dataframe_train.BsmtFinSF1)',\n",
      "       'feature_FullBath.MEAN(dataframe_train.BsmtFinSF2)',\n",
      "       'feature_FullBath.MEAN(dataframe_train.BsmtUnfSF)',\n",
      "       'feature_FullBath.MEAN(dataframe_train.TotalBsmtSF)',\n",
      "       'feature_FullBath.MEAN(dataframe_train.1stFlrSF)',\n",
      "       'feature_FullBath.MEAN(dataframe_train.2ndFlrSF)'],\n",
      "      dtype='object')\n",
      "the are 1 datasets provided\n",
      "the number of classes in HalfBath feature is: 3\n",
      "Index(['feature_HalfBath.MIN(dataframe_train.1stFlrSF)',\n",
      "       'feature_HalfBath.MIN(dataframe_train.2ndFlrSF)',\n",
      "       'feature_HalfBath.MIN(dataframe_train.GrLivArea)',\n",
      "       'feature_HalfBath.MIN(dataframe_train.GarageYrBlt)',\n",
      "       'feature_HalfBath.MIN(dataframe_train.GarageArea)',\n",
      "       'feature_HalfBath.MIN(dataframe_train.WoodDeckSF)',\n",
      "       'feature_HalfBath.MIN(dataframe_train.OpenPorchSF)',\n",
      "       'feature_HalfBath.MIN(dataframe_train.EnclosedPorch)',\n",
      "       'feature_HalfBath.MIN(dataframe_train.ScreenPorch)',\n",
      "       'feature_HalfBath.MEAN(dataframe_train.LotFrontage)',\n",
      "       'feature_HalfBath.MEAN(dataframe_train.LotArea)',\n",
      "       'feature_HalfBath.MEAN(dataframe_train.YearBuilt)',\n",
      "       'feature_HalfBath.MEAN(dataframe_train.YearRemodAdd)',\n",
      "       'feature_HalfBath.MEAN(dataframe_train.MasVnrArea)',\n",
      "       'feature_HalfBath.MEAN(dataframe_train.BsmtFinSF1)',\n",
      "       'feature_HalfBath.MEAN(dataframe_train.BsmtFinSF2)',\n",
      "       'feature_HalfBath.MEAN(dataframe_train.BsmtUnfSF)',\n",
      "       'feature_HalfBath.MEAN(dataframe_train.TotalBsmtSF)',\n",
      "       'feature_HalfBath.MEAN(dataframe_train.1stFlrSF)',\n",
      "       'feature_HalfBath.MEAN(dataframe_train.2ndFlrSF)'],\n",
      "      dtype='object')\n",
      "the are 1 datasets provided\n",
      "the number of classes in BedroomAbvGr feature is: 8\n",
      "Index(['feature_BedroomAbvGr.MIN(dataframe_train.1stFlrSF)',\n",
      "       'feature_BedroomAbvGr.MIN(dataframe_train.2ndFlrSF)',\n",
      "       'feature_BedroomAbvGr.MIN(dataframe_train.GrLivArea)',\n",
      "       'feature_BedroomAbvGr.MIN(dataframe_train.GarageYrBlt)',\n",
      "       'feature_BedroomAbvGr.MIN(dataframe_train.GarageArea)',\n",
      "       'feature_BedroomAbvGr.MIN(dataframe_train.WoodDeckSF)',\n",
      "       'feature_BedroomAbvGr.MIN(dataframe_train.OpenPorchSF)',\n",
      "       'feature_BedroomAbvGr.MIN(dataframe_train.EnclosedPorch)',\n",
      "       'feature_BedroomAbvGr.MIN(dataframe_train.ScreenPorch)',\n",
      "       'feature_BedroomAbvGr.MEAN(dataframe_train.LotFrontage)',\n",
      "       'feature_BedroomAbvGr.MEAN(dataframe_train.LotArea)',\n",
      "       'feature_BedroomAbvGr.MEAN(dataframe_train.YearBuilt)',\n",
      "       'feature_BedroomAbvGr.MEAN(dataframe_train.YearRemodAdd)',\n",
      "       'feature_BedroomAbvGr.MEAN(dataframe_train.MasVnrArea)',\n",
      "       'feature_BedroomAbvGr.MEAN(dataframe_train.BsmtFinSF1)',\n",
      "       'feature_BedroomAbvGr.MEAN(dataframe_train.BsmtFinSF2)',\n",
      "       'feature_BedroomAbvGr.MEAN(dataframe_train.BsmtUnfSF)',\n",
      "       'feature_BedroomAbvGr.MEAN(dataframe_train.TotalBsmtSF)',\n",
      "       'feature_BedroomAbvGr.MEAN(dataframe_train.1stFlrSF)',\n",
      "       'feature_BedroomAbvGr.MEAN(dataframe_train.2ndFlrSF)'],\n",
      "      dtype='object')\n",
      "the are 1 datasets provided\n",
      "the number of classes in KitchenAbvGr feature is: 4\n",
      "Index(['feature_KitchenAbvGr.MIN(dataframe_train.1stFlrSF)',\n",
      "       'feature_KitchenAbvGr.MIN(dataframe_train.2ndFlrSF)',\n",
      "       'feature_KitchenAbvGr.MIN(dataframe_train.GrLivArea)',\n",
      "       'feature_KitchenAbvGr.MIN(dataframe_train.GarageYrBlt)',\n",
      "       'feature_KitchenAbvGr.MIN(dataframe_train.GarageArea)',\n",
      "       'feature_KitchenAbvGr.MIN(dataframe_train.WoodDeckSF)',\n",
      "       'feature_KitchenAbvGr.MIN(dataframe_train.OpenPorchSF)',\n",
      "       'feature_KitchenAbvGr.MIN(dataframe_train.EnclosedPorch)',\n",
      "       'feature_KitchenAbvGr.MIN(dataframe_train.ScreenPorch)',\n",
      "       'feature_KitchenAbvGr.MEAN(dataframe_train.LotFrontage)',\n",
      "       'feature_KitchenAbvGr.MEAN(dataframe_train.LotArea)',\n",
      "       'feature_KitchenAbvGr.MEAN(dataframe_train.YearBuilt)',\n",
      "       'feature_KitchenAbvGr.MEAN(dataframe_train.YearRemodAdd)',\n",
      "       'feature_KitchenAbvGr.MEAN(dataframe_train.MasVnrArea)',\n",
      "       'feature_KitchenAbvGr.MEAN(dataframe_train.BsmtFinSF1)',\n",
      "       'feature_KitchenAbvGr.MEAN(dataframe_train.BsmtFinSF2)',\n",
      "       'feature_KitchenAbvGr.MEAN(dataframe_train.BsmtUnfSF)',\n",
      "       'feature_KitchenAbvGr.MEAN(dataframe_train.TotalBsmtSF)',\n",
      "       'feature_KitchenAbvGr.MEAN(dataframe_train.1stFlrSF)',\n",
      "       'feature_KitchenAbvGr.MEAN(dataframe_train.2ndFlrSF)'],\n",
      "      dtype='object')\n",
      "the are 1 datasets provided\n",
      "the number of classes in TotRmsAbvGrd feature is: 12\n",
      "Index(['feature_TotRmsAbvGrd.MIN(dataframe_train.1stFlrSF)',\n",
      "       'feature_TotRmsAbvGrd.MIN(dataframe_train.2ndFlrSF)',\n",
      "       'feature_TotRmsAbvGrd.MIN(dataframe_train.GrLivArea)',\n",
      "       'feature_TotRmsAbvGrd.MIN(dataframe_train.GarageYrBlt)',\n",
      "       'feature_TotRmsAbvGrd.MIN(dataframe_train.GarageArea)',\n",
      "       'feature_TotRmsAbvGrd.MIN(dataframe_train.WoodDeckSF)',\n",
      "       'feature_TotRmsAbvGrd.MIN(dataframe_train.OpenPorchSF)',\n",
      "       'feature_TotRmsAbvGrd.MIN(dataframe_train.EnclosedPorch)',\n",
      "       'feature_TotRmsAbvGrd.MIN(dataframe_train.ScreenPorch)',\n",
      "       'feature_TotRmsAbvGrd.MEAN(dataframe_train.LotFrontage)',\n",
      "       'feature_TotRmsAbvGrd.MEAN(dataframe_train.LotArea)',\n",
      "       'feature_TotRmsAbvGrd.MEAN(dataframe_train.YearBuilt)',\n",
      "       'feature_TotRmsAbvGrd.MEAN(dataframe_train.YearRemodAdd)',\n",
      "       'feature_TotRmsAbvGrd.MEAN(dataframe_train.MasVnrArea)',\n",
      "       'feature_TotRmsAbvGrd.MEAN(dataframe_train.BsmtFinSF1)',\n",
      "       'feature_TotRmsAbvGrd.MEAN(dataframe_train.BsmtFinSF2)',\n",
      "       'feature_TotRmsAbvGrd.MEAN(dataframe_train.BsmtUnfSF)',\n",
      "       'feature_TotRmsAbvGrd.MEAN(dataframe_train.TotalBsmtSF)',\n",
      "       'feature_TotRmsAbvGrd.MEAN(dataframe_train.1stFlrSF)',\n",
      "       'feature_TotRmsAbvGrd.MEAN(dataframe_train.2ndFlrSF)'],\n",
      "      dtype='object')\n",
      "the are 1 datasets provided\n",
      "the number of classes in Fireplaces feature is: 4\n",
      "Index(['feature_Fireplaces.MIN(dataframe_train.1stFlrSF)',\n",
      "       'feature_Fireplaces.MIN(dataframe_train.2ndFlrSF)',\n",
      "       'feature_Fireplaces.MIN(dataframe_train.GrLivArea)',\n",
      "       'feature_Fireplaces.MIN(dataframe_train.GarageYrBlt)',\n",
      "       'feature_Fireplaces.MIN(dataframe_train.GarageArea)',\n",
      "       'feature_Fireplaces.MIN(dataframe_train.WoodDeckSF)',\n",
      "       'feature_Fireplaces.MIN(dataframe_train.OpenPorchSF)',\n",
      "       'feature_Fireplaces.MIN(dataframe_train.EnclosedPorch)',\n",
      "       'feature_Fireplaces.MIN(dataframe_train.ScreenPorch)',\n",
      "       'feature_Fireplaces.MEAN(dataframe_train.LotFrontage)',\n",
      "       'feature_Fireplaces.MEAN(dataframe_train.LotArea)',\n",
      "       'feature_Fireplaces.MEAN(dataframe_train.YearBuilt)',\n",
      "       'feature_Fireplaces.MEAN(dataframe_train.YearRemodAdd)',\n",
      "       'feature_Fireplaces.MEAN(dataframe_train.MasVnrArea)',\n",
      "       'feature_Fireplaces.MEAN(dataframe_train.BsmtFinSF1)',\n",
      "       'feature_Fireplaces.MEAN(dataframe_train.BsmtFinSF2)',\n",
      "       'feature_Fireplaces.MEAN(dataframe_train.BsmtUnfSF)',\n",
      "       'feature_Fireplaces.MEAN(dataframe_train.TotalBsmtSF)',\n",
      "       'feature_Fireplaces.MEAN(dataframe_train.1stFlrSF)',\n",
      "       'feature_Fireplaces.MEAN(dataframe_train.2ndFlrSF)'],\n",
      "      dtype='object')\n",
      "the are 1 datasets provided\n",
      "the number of classes in GarageCars feature is: 5\n",
      "Index(['feature_GarageCars.MIN(dataframe_train.1stFlrSF)',\n",
      "       'feature_GarageCars.MIN(dataframe_train.2ndFlrSF)',\n",
      "       'feature_GarageCars.MIN(dataframe_train.GrLivArea)',\n",
      "       'feature_GarageCars.MIN(dataframe_train.GarageYrBlt)',\n",
      "       'feature_GarageCars.MIN(dataframe_train.GarageArea)',\n",
      "       'feature_GarageCars.MIN(dataframe_train.WoodDeckSF)',\n",
      "       'feature_GarageCars.MIN(dataframe_train.OpenPorchSF)',\n",
      "       'feature_GarageCars.MIN(dataframe_train.EnclosedPorch)',\n",
      "       'feature_GarageCars.MIN(dataframe_train.ScreenPorch)',\n",
      "       'feature_GarageCars.MEAN(dataframe_train.LotFrontage)',\n",
      "       'feature_GarageCars.MEAN(dataframe_train.LotArea)',\n",
      "       'feature_GarageCars.MEAN(dataframe_train.YearBuilt)',\n",
      "       'feature_GarageCars.MEAN(dataframe_train.YearRemodAdd)',\n",
      "       'feature_GarageCars.MEAN(dataframe_train.MasVnrArea)',\n",
      "       'feature_GarageCars.MEAN(dataframe_train.BsmtFinSF1)',\n",
      "       'feature_GarageCars.MEAN(dataframe_train.BsmtFinSF2)',\n",
      "       'feature_GarageCars.MEAN(dataframe_train.BsmtUnfSF)',\n",
      "       'feature_GarageCars.MEAN(dataframe_train.TotalBsmtSF)',\n",
      "       'feature_GarageCars.MEAN(dataframe_train.1stFlrSF)',\n",
      "       'feature_GarageCars.MEAN(dataframe_train.2ndFlrSF)'],\n",
      "      dtype='object')\n",
      "the are 1 datasets provided\n",
      "the number of classes in 3SsnPorch feature is: 20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['feature_3SsnPorch.MIN(dataframe_train.1stFlrSF)',\n",
      "       'feature_3SsnPorch.MIN(dataframe_train.2ndFlrSF)',\n",
      "       'feature_3SsnPorch.MIN(dataframe_train.GrLivArea)',\n",
      "       'feature_3SsnPorch.MIN(dataframe_train.GarageYrBlt)',\n",
      "       'feature_3SsnPorch.MIN(dataframe_train.GarageArea)',\n",
      "       'feature_3SsnPorch.MIN(dataframe_train.WoodDeckSF)',\n",
      "       'feature_3SsnPorch.MIN(dataframe_train.OpenPorchSF)',\n",
      "       'feature_3SsnPorch.MIN(dataframe_train.EnclosedPorch)',\n",
      "       'feature_3SsnPorch.MIN(dataframe_train.ScreenPorch)',\n",
      "       'feature_3SsnPorch.MEAN(dataframe_train.LotFrontage)',\n",
      "       'feature_3SsnPorch.MEAN(dataframe_train.LotArea)',\n",
      "       'feature_3SsnPorch.MEAN(dataframe_train.YearBuilt)',\n",
      "       'feature_3SsnPorch.MEAN(dataframe_train.YearRemodAdd)',\n",
      "       'feature_3SsnPorch.MEAN(dataframe_train.MasVnrArea)',\n",
      "       'feature_3SsnPorch.MEAN(dataframe_train.BsmtFinSF1)',\n",
      "       'feature_3SsnPorch.MEAN(dataframe_train.BsmtFinSF2)',\n",
      "       'feature_3SsnPorch.MEAN(dataframe_train.BsmtUnfSF)',\n",
      "       'feature_3SsnPorch.MEAN(dataframe_train.TotalBsmtSF)',\n",
      "       'feature_3SsnPorch.MEAN(dataframe_train.1stFlrSF)',\n",
      "       'feature_3SsnPorch.MEAN(dataframe_train.2ndFlrSF)'],\n",
      "      dtype='object')\n",
      "the are 1 datasets provided\n",
      "the number of classes in PoolArea feature is: 8\n",
      "Index(['feature_PoolArea.MIN(dataframe_train.1stFlrSF)',\n",
      "       'feature_PoolArea.MIN(dataframe_train.2ndFlrSF)',\n",
      "       'feature_PoolArea.MIN(dataframe_train.GrLivArea)',\n",
      "       'feature_PoolArea.MIN(dataframe_train.GarageYrBlt)',\n",
      "       'feature_PoolArea.MIN(dataframe_train.GarageArea)',\n",
      "       'feature_PoolArea.MIN(dataframe_train.WoodDeckSF)',\n",
      "       'feature_PoolArea.MIN(dataframe_train.OpenPorchSF)',\n",
      "       'feature_PoolArea.MIN(dataframe_train.EnclosedPorch)',\n",
      "       'feature_PoolArea.MIN(dataframe_train.ScreenPorch)',\n",
      "       'feature_PoolArea.MEAN(dataframe_train.LotFrontage)',\n",
      "       'feature_PoolArea.MEAN(dataframe_train.LotArea)',\n",
      "       'feature_PoolArea.MEAN(dataframe_train.YearBuilt)',\n",
      "       'feature_PoolArea.MEAN(dataframe_train.YearRemodAdd)',\n",
      "       'feature_PoolArea.MEAN(dataframe_train.MasVnrArea)',\n",
      "       'feature_PoolArea.MEAN(dataframe_train.BsmtFinSF1)',\n",
      "       'feature_PoolArea.MEAN(dataframe_train.BsmtFinSF2)',\n",
      "       'feature_PoolArea.MEAN(dataframe_train.BsmtUnfSF)',\n",
      "       'feature_PoolArea.MEAN(dataframe_train.TotalBsmtSF)',\n",
      "       'feature_PoolArea.MEAN(dataframe_train.1stFlrSF)',\n",
      "       'feature_PoolArea.MEAN(dataframe_train.2ndFlrSF)'],\n",
      "      dtype='object')\n",
      "the are 1 datasets provided\n",
      "the number of classes in MiscVal feature is: 21\n",
      "Index(['feature_MiscVal.MIN(dataframe_train.1stFlrSF)',\n",
      "       'feature_MiscVal.MIN(dataframe_train.2ndFlrSF)',\n",
      "       'feature_MiscVal.MIN(dataframe_train.GrLivArea)',\n",
      "       'feature_MiscVal.MIN(dataframe_train.GarageYrBlt)',\n",
      "       'feature_MiscVal.MIN(dataframe_train.GarageArea)',\n",
      "       'feature_MiscVal.MIN(dataframe_train.WoodDeckSF)',\n",
      "       'feature_MiscVal.MIN(dataframe_train.OpenPorchSF)',\n",
      "       'feature_MiscVal.MIN(dataframe_train.EnclosedPorch)',\n",
      "       'feature_MiscVal.MIN(dataframe_train.ScreenPorch)',\n",
      "       'feature_MiscVal.MEAN(dataframe_train.LotFrontage)',\n",
      "       'feature_MiscVal.MEAN(dataframe_train.LotArea)',\n",
      "       'feature_MiscVal.MEAN(dataframe_train.YearBuilt)',\n",
      "       'feature_MiscVal.MEAN(dataframe_train.YearRemodAdd)',\n",
      "       'feature_MiscVal.MEAN(dataframe_train.MasVnrArea)',\n",
      "       'feature_MiscVal.MEAN(dataframe_train.BsmtFinSF1)',\n",
      "       'feature_MiscVal.MEAN(dataframe_train.BsmtFinSF2)',\n",
      "       'feature_MiscVal.MEAN(dataframe_train.BsmtUnfSF)',\n",
      "       'feature_MiscVal.MEAN(dataframe_train.TotalBsmtSF)',\n",
      "       'feature_MiscVal.MEAN(dataframe_train.1stFlrSF)',\n",
      "       'feature_MiscVal.MEAN(dataframe_train.2ndFlrSF)'],\n",
      "      dtype='object')\n",
      "the are 1 datasets provided\n",
      "the number of classes in MoSold feature is: 12\n",
      "Index(['feature_MoSold.MIN(dataframe_train.1stFlrSF)',\n",
      "       'feature_MoSold.MIN(dataframe_train.2ndFlrSF)',\n",
      "       'feature_MoSold.MIN(dataframe_train.GrLivArea)',\n",
      "       'feature_MoSold.MIN(dataframe_train.GarageYrBlt)',\n",
      "       'feature_MoSold.MIN(dataframe_train.GarageArea)',\n",
      "       'feature_MoSold.MIN(dataframe_train.WoodDeckSF)',\n",
      "       'feature_MoSold.MIN(dataframe_train.OpenPorchSF)',\n",
      "       'feature_MoSold.MIN(dataframe_train.EnclosedPorch)',\n",
      "       'feature_MoSold.MIN(dataframe_train.ScreenPorch)',\n",
      "       'feature_MoSold.MEAN(dataframe_train.LotFrontage)',\n",
      "       'feature_MoSold.MEAN(dataframe_train.LotArea)',\n",
      "       'feature_MoSold.MEAN(dataframe_train.YearBuilt)',\n",
      "       'feature_MoSold.MEAN(dataframe_train.YearRemodAdd)',\n",
      "       'feature_MoSold.MEAN(dataframe_train.MasVnrArea)',\n",
      "       'feature_MoSold.MEAN(dataframe_train.BsmtFinSF1)',\n",
      "       'feature_MoSold.MEAN(dataframe_train.BsmtFinSF2)',\n",
      "       'feature_MoSold.MEAN(dataframe_train.BsmtUnfSF)',\n",
      "       'feature_MoSold.MEAN(dataframe_train.TotalBsmtSF)',\n",
      "       'feature_MoSold.MEAN(dataframe_train.1stFlrSF)',\n",
      "       'feature_MoSold.MEAN(dataframe_train.2ndFlrSF)'],\n",
      "      dtype='object')\n",
      "the are 1 datasets provided\n",
      "the number of classes in YrSold feature is: 5\n",
      "Index(['feature_YrSold.MIN(dataframe_train.1stFlrSF)',\n",
      "       'feature_YrSold.MIN(dataframe_train.2ndFlrSF)',\n",
      "       'feature_YrSold.MIN(dataframe_train.GrLivArea)',\n",
      "       'feature_YrSold.MIN(dataframe_train.GarageYrBlt)',\n",
      "       'feature_YrSold.MIN(dataframe_train.GarageArea)',\n",
      "       'feature_YrSold.MIN(dataframe_train.WoodDeckSF)',\n",
      "       'feature_YrSold.MIN(dataframe_train.OpenPorchSF)',\n",
      "       'feature_YrSold.MIN(dataframe_train.EnclosedPorch)',\n",
      "       'feature_YrSold.MIN(dataframe_train.ScreenPorch)',\n",
      "       'feature_YrSold.MEAN(dataframe_train.LotFrontage)',\n",
      "       'feature_YrSold.MEAN(dataframe_train.LotArea)',\n",
      "       'feature_YrSold.MEAN(dataframe_train.YearBuilt)',\n",
      "       'feature_YrSold.MEAN(dataframe_train.YearRemodAdd)',\n",
      "       'feature_YrSold.MEAN(dataframe_train.MasVnrArea)',\n",
      "       'feature_YrSold.MEAN(dataframe_train.BsmtFinSF1)',\n",
      "       'feature_YrSold.MEAN(dataframe_train.BsmtFinSF2)',\n",
      "       'feature_YrSold.MEAN(dataframe_train.BsmtUnfSF)',\n",
      "       'feature_YrSold.MEAN(dataframe_train.TotalBsmtSF)',\n",
      "       'feature_YrSold.MEAN(dataframe_train.1stFlrSF)',\n",
      "       'feature_YrSold.MEAN(dataframe_train.2ndFlrSF)'],\n",
      "      dtype='object')\n",
      "(1460, 110)\n"
     ]
    }
   ],
   "source": [
    "categorical_columns = ['MSSubClass', 'OverallQual', 'OverallCond', 'LowQualFinSF', 'BsmtFullBath', 'BsmtHalfBath',\n",
    "                       'FullBath', 'HalfBath', 'BedroomAbvGr', 'KitchenAbvGr', 'TotRmsAbvGrd', 'Fireplaces',\n",
    "                       'GarageCars', '3SsnPorch', 'PoolArea', 'MiscVal', 'MoSold', 'YrSold']\n",
    "\n",
    "train_dataframe.index = range(train_dataframe.shape[0])\n",
    "\n",
    "max_depth = 2\n",
    "train_dataframe_list = []\n",
    "for aggregate_feature in categorical_columns:\n",
    "    numerical_columns = ['Id', 'LotFrontage', 'LotArea', 'YearBuilt', 'YearRemodAdd', 'MasVnrArea', 'BsmtFinSF1',\n",
    "                         'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF', '1stFlrSF', '2ndFlrSF', 'GrLivArea', 'GarageYrBlt',\n",
    "                         'GarageArea', 'WoodDeckSF', 'OpenPorchSF', 'EnclosedPorch', 'ScreenPorch', aggregate_feature]\n",
    "\n",
    "    train_dataframe_considered = train_dataframe[numerical_columns]\n",
    "\n",
    "    dataset_list = []\n",
    "    dataset_list.append(train_dataframe_considered[aggregate_feature].astype(str))\n",
    "\n",
    "    dataset_list, class_labels = encoding_categorical_features(\n",
    "        aggregate_feature, dataset_list)\n",
    "\n",
    "    train_dataframe_considered[aggregate_feature] = dataset_list[0]\n",
    "\n",
    "    feature_matrix_train = automated_feature_extraction(train_dataframe_considered, [aggregate_feature], max_depth)\n",
    "    print(feature_matrix_train.columns[100:120])\n",
    "    feature_matrix_train = feature_matrix_train.drop(numerical_columns[1:len(numerical_columns)-1], axis=1)\n",
    "\n",
    "    columns = ['{}_{}'.format(aggregate_feature,x) for x in range(feature_matrix_train.shape[1])]\n",
    "    feature_matrix_train.columns = columns\n",
    "    feature_matrix_train.index = range(feature_matrix_train.shape[0])\n",
    "\n",
    "    train_dataframe_list.append(feature_matrix_train)\n",
    "print(feature_matrix_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# brining all feature together in a dataframe\n",
    "train_dataframe_list.append(train_dataframe[numerical_columns[1:len(numerical_columns)-1]])\n",
    "feature_matrix_train = pd.concat(train_dataframe_list, axis=1,ignore_index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSSubClass_0</th>\n",
       "      <th>MSSubClass_1</th>\n",
       "      <th>MSSubClass_2</th>\n",
       "      <th>MSSubClass_3</th>\n",
       "      <th>MSSubClass_4</th>\n",
       "      <th>MSSubClass_5</th>\n",
       "      <th>MSSubClass_6</th>\n",
       "      <th>MSSubClass_7</th>\n",
       "      <th>MSSubClass_8</th>\n",
       "      <th>MSSubClass_9</th>\n",
       "      <th>...</th>\n",
       "      <th>TotalBsmtSF</th>\n",
       "      <th>1stFlrSF</th>\n",
       "      <th>2ndFlrSF</th>\n",
       "      <th>GrLivArea</th>\n",
       "      <th>GarageYrBlt</th>\n",
       "      <th>GarageArea</th>\n",
       "      <th>WoodDeckSF</th>\n",
       "      <th>OpenPorchSF</th>\n",
       "      <th>EnclosedPorch</th>\n",
       "      <th>ScreenPorch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9</td>\n",
       "      <td>104.286186</td>\n",
       "      <td>46.185660</td>\n",
       "      <td>230.021092</td>\n",
       "      <td>166.105438</td>\n",
       "      <td>126.677765</td>\n",
       "      <td>-2.042537</td>\n",
       "      <td>-34.615566</td>\n",
       "      <td>-2.487761</td>\n",
       "      <td>-17.357926</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.459303</td>\n",
       "      <td>-0.793434</td>\n",
       "      <td>1.161852</td>\n",
       "      <td>0.370333</td>\n",
       "      <td>0.992426</td>\n",
       "      <td>0.351000</td>\n",
       "      <td>-0.752176</td>\n",
       "      <td>0.216503</td>\n",
       "      <td>-0.359325</td>\n",
       "      <td>-0.270208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>133.479560</td>\n",
       "      <td>66.540728</td>\n",
       "      <td>118.819171</td>\n",
       "      <td>26.308138</td>\n",
       "      <td>1.969244</td>\n",
       "      <td>140.303209</td>\n",
       "      <td>84.455090</td>\n",
       "      <td>67.949014</td>\n",
       "      <td>245.359874</td>\n",
       "      <td>...</td>\n",
       "      <td>0.466465</td>\n",
       "      <td>0.257140</td>\n",
       "      <td>-0.795163</td>\n",
       "      <td>-0.482512</td>\n",
       "      <td>-0.101543</td>\n",
       "      <td>-0.060731</td>\n",
       "      <td>1.626195</td>\n",
       "      <td>-0.704483</td>\n",
       "      <td>-0.359325</td>\n",
       "      <td>-0.270208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>104.286186</td>\n",
       "      <td>46.185660</td>\n",
       "      <td>230.021092</td>\n",
       "      <td>166.105438</td>\n",
       "      <td>126.677765</td>\n",
       "      <td>-2.042537</td>\n",
       "      <td>-34.615566</td>\n",
       "      <td>-2.487761</td>\n",
       "      <td>-17.357926</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.313369</td>\n",
       "      <td>-0.627826</td>\n",
       "      <td>1.189351</td>\n",
       "      <td>0.515013</td>\n",
       "      <td>0.911391</td>\n",
       "      <td>0.631726</td>\n",
       "      <td>-0.752176</td>\n",
       "      <td>-0.070361</td>\n",
       "      <td>-0.359325</td>\n",
       "      <td>-0.270208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>-9.958859</td>\n",
       "      <td>-2.385253</td>\n",
       "      <td>-104.200128</td>\n",
       "      <td>-20.347824</td>\n",
       "      <td>-33.132532</td>\n",
       "      <td>-34.430669</td>\n",
       "      <td>-15.086806</td>\n",
       "      <td>5.190162</td>\n",
       "      <td>-36.115801</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.687324</td>\n",
       "      <td>-0.521734</td>\n",
       "      <td>0.937276</td>\n",
       "      <td>0.383659</td>\n",
       "      <td>0.789839</td>\n",
       "      <td>0.790804</td>\n",
       "      <td>-0.752176</td>\n",
       "      <td>-0.176048</td>\n",
       "      <td>4.092524</td>\n",
       "      <td>-0.270208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>104.286186</td>\n",
       "      <td>46.185660</td>\n",
       "      <td>230.021092</td>\n",
       "      <td>166.105438</td>\n",
       "      <td>126.677765</td>\n",
       "      <td>-2.042537</td>\n",
       "      <td>-34.615566</td>\n",
       "      <td>-2.487761</td>\n",
       "      <td>-17.357926</td>\n",
       "      <td>...</td>\n",
       "      <td>0.199680</td>\n",
       "      <td>-0.045611</td>\n",
       "      <td>1.617877</td>\n",
       "      <td>1.299326</td>\n",
       "      <td>0.870874</td>\n",
       "      <td>1.698485</td>\n",
       "      <td>0.780197</td>\n",
       "      <td>0.563760</td>\n",
       "      <td>-0.359325</td>\n",
       "      <td>-0.270208</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  1998 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   MSSubClass_0  MSSubClass_1  MSSubClass_2  MSSubClass_3  MSSubClass_4  \\\n",
       "0             9    104.286186     46.185660    230.021092    166.105438   \n",
       "1             4    133.479560     66.540728    118.819171     26.308138   \n",
       "2             9    104.286186     46.185660    230.021092    166.105438   \n",
       "3            10     -9.958859     -2.385253   -104.200128    -20.347824   \n",
       "4             9    104.286186     46.185660    230.021092    166.105438   \n",
       "\n",
       "   MSSubClass_5  MSSubClass_6  MSSubClass_7  MSSubClass_8  MSSubClass_9  \\\n",
       "0    126.677765     -2.042537    -34.615566     -2.487761    -17.357926   \n",
       "1      1.969244    140.303209     84.455090     67.949014    245.359874   \n",
       "2    126.677765     -2.042537    -34.615566     -2.487761    -17.357926   \n",
       "3    -33.132532    -34.430669    -15.086806      5.190162    -36.115801   \n",
       "4    126.677765     -2.042537    -34.615566     -2.487761    -17.357926   \n",
       "\n",
       "      ...       TotalBsmtSF  1stFlrSF  2ndFlrSF  GrLivArea  GarageYrBlt  \\\n",
       "0     ...         -0.459303 -0.793434  1.161852   0.370333     0.992426   \n",
       "1     ...          0.466465  0.257140 -0.795163  -0.482512    -0.101543   \n",
       "2     ...         -0.313369 -0.627826  1.189351   0.515013     0.911391   \n",
       "3     ...         -0.687324 -0.521734  0.937276   0.383659     0.789839   \n",
       "4     ...          0.199680 -0.045611  1.617877   1.299326     0.870874   \n",
       "\n",
       "   GarageArea  WoodDeckSF  OpenPorchSF  EnclosedPorch  ScreenPorch  \n",
       "0    0.351000   -0.752176     0.216503      -0.359325    -0.270208  \n",
       "1   -0.060731    1.626195    -0.704483      -0.359325    -0.270208  \n",
       "2    0.631726   -0.752176    -0.070361      -0.359325    -0.270208  \n",
       "3    0.790804   -0.752176    -0.176048       4.092524    -0.270208  \n",
       "4    1.698485    0.780197     0.563760      -0.359325    -0.270208  \n",
       "\n",
       "[5 rows x 1998 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_matrix_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>type</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sum</td>\n",
       "      <td>aggregation</td>\n",
       "      <td>Calculates the total addition, ignoring `NaN`.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>std</td>\n",
       "      <td>aggregation</td>\n",
       "      <td>Computes the dispersion relative to the mean v...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>avg_time_between</td>\n",
       "      <td>aggregation</td>\n",
       "      <td>Computes the average number of seconds between...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>count</td>\n",
       "      <td>aggregation</td>\n",
       "      <td>Determines the total number of values, excludi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>median</td>\n",
       "      <td>aggregation</td>\n",
       "      <td>Determines the middlemost number in a list of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>percent_true</td>\n",
       "      <td>aggregation</td>\n",
       "      <td>Determines the percent of `True` values.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>num_unique</td>\n",
       "      <td>aggregation</td>\n",
       "      <td>Determines the number of distinct values, igno...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>trend</td>\n",
       "      <td>aggregation</td>\n",
       "      <td>Calculates the trend of a variable over time.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>min</td>\n",
       "      <td>aggregation</td>\n",
       "      <td>Calculates the smallest value, ignoring `NaN` ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>all</td>\n",
       "      <td>aggregation</td>\n",
       "      <td>Calculates if all values are 'True' in a list.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>mean</td>\n",
       "      <td>aggregation</td>\n",
       "      <td>Computes the average for a list of values.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>last</td>\n",
       "      <td>aggregation</td>\n",
       "      <td>Determines the last value in a list.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>skew</td>\n",
       "      <td>aggregation</td>\n",
       "      <td>Computes the extent to which a distribution di...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>time_since_first</td>\n",
       "      <td>aggregation</td>\n",
       "      <td>Calculates the time elapsed since the first da...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>n_most_common</td>\n",
       "      <td>aggregation</td>\n",
       "      <td>Determines the `n` most common elements.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>num_true</td>\n",
       "      <td>aggregation</td>\n",
       "      <td>Counts the number of `True` values.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>max</td>\n",
       "      <td>aggregation</td>\n",
       "      <td>Calculates the highest value, ignoring `NaN` v...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>time_since_last</td>\n",
       "      <td>aggregation</td>\n",
       "      <td>Calculates the time elapsed since the last dat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>mode</td>\n",
       "      <td>aggregation</td>\n",
       "      <td>Determines the most commonly repeated value.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>any</td>\n",
       "      <td>aggregation</td>\n",
       "      <td>Determines if any value is 'True' in a list.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>month</td>\n",
       "      <td>transform</td>\n",
       "      <td>Determines the month value of a datetime.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>divide_numeric</td>\n",
       "      <td>transform</td>\n",
       "      <td>Element-wise division of two lists.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>and</td>\n",
       "      <td>transform</td>\n",
       "      <td>Element-wise logical AND of two lists.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>diff</td>\n",
       "      <td>transform</td>\n",
       "      <td>Compute the difference between the value in a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>equal</td>\n",
       "      <td>transform</td>\n",
       "      <td>Determines if values in one list are equal to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>is_null</td>\n",
       "      <td>transform</td>\n",
       "      <td>Determines if a value is null.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>multiply_numeric</td>\n",
       "      <td>transform</td>\n",
       "      <td>Element-wise multiplication of two lists.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>less_than_equal_to</td>\n",
       "      <td>transform</td>\n",
       "      <td>Determines if values in one list are less than...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>days_since</td>\n",
       "      <td>transform</td>\n",
       "      <td>Calculates the number of days from a value to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>modulo_numeric_scalar</td>\n",
       "      <td>transform</td>\n",
       "      <td>Return the modulo of each element in the list ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>year</td>\n",
       "      <td>transform</td>\n",
       "      <td>Determines the year value of a datetime.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>cum_sum</td>\n",
       "      <td>transform</td>\n",
       "      <td>Calculates the cumulative sum.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>time_since_previous</td>\n",
       "      <td>transform</td>\n",
       "      <td>Compute the time in seconds since the previous...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>equal_scalar</td>\n",
       "      <td>transform</td>\n",
       "      <td>Determines if values in a list are equal to a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>negate</td>\n",
       "      <td>transform</td>\n",
       "      <td>Negates a numeric value.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>or</td>\n",
       "      <td>transform</td>\n",
       "      <td>Element-wise logical OR of two lists.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>absolute</td>\n",
       "      <td>transform</td>\n",
       "      <td>Computes the absolute value of a number.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>multiply_numeric_scalar</td>\n",
       "      <td>transform</td>\n",
       "      <td>Multiply each element in the list by a scalar.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>less_than_equal_to_scalar</td>\n",
       "      <td>transform</td>\n",
       "      <td>Determines if values are less than or equal to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>isin</td>\n",
       "      <td>transform</td>\n",
       "      <td>Determines whether a value is present in a pro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>modulo_by_feature</td>\n",
       "      <td>transform</td>\n",
       "      <td>Return the modulo of a scalar by each element ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>scalar_subtract_numeric_feature</td>\n",
       "      <td>transform</td>\n",
       "      <td>Subtract each value in the list from a given s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>less_than_scalar</td>\n",
       "      <td>transform</td>\n",
       "      <td>Determines if values are less than a given sca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>modulo_numeric</td>\n",
       "      <td>transform</td>\n",
       "      <td>Element-wise modulo of two lists.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>time_since</td>\n",
       "      <td>transform</td>\n",
       "      <td>Calculates time in nanoseconds from a value to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>minute</td>\n",
       "      <td>transform</td>\n",
       "      <td>Determines the minutes value of a datetime.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>subtract_numeric</td>\n",
       "      <td>transform</td>\n",
       "      <td>Element-wise subtraction of two lists.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>haversine</td>\n",
       "      <td>transform</td>\n",
       "      <td>Calculates the approximate haversine distance ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>divide_numeric_scalar</td>\n",
       "      <td>transform</td>\n",
       "      <td>Divide each element in the list by a scalar.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>greater_than_equal_to_scalar</td>\n",
       "      <td>transform</td>\n",
       "      <td>Determines if values are greater than or equal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>num_characters</td>\n",
       "      <td>transform</td>\n",
       "      <td>Calculates the number of characters in a string.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>cum_min</td>\n",
       "      <td>transform</td>\n",
       "      <td>Calculates the cumulative minimum.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>hour</td>\n",
       "      <td>transform</td>\n",
       "      <td>Determines the hour value of a datetime.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>add_numeric</td>\n",
       "      <td>transform</td>\n",
       "      <td>Element-wise addition of two lists.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>latitude</td>\n",
       "      <td>transform</td>\n",
       "      <td>Returns the first tuple value in a list of Lat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>greater_than_scalar</td>\n",
       "      <td>transform</td>\n",
       "      <td>Determines if values are greater than a given ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>is_weekend</td>\n",
       "      <td>transform</td>\n",
       "      <td>Determines if a date falls on a weekend.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>cum_count</td>\n",
       "      <td>transform</td>\n",
       "      <td>Calculates the cumulative count.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>not_equal</td>\n",
       "      <td>transform</td>\n",
       "      <td>Determines if values in one list are not equal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>not</td>\n",
       "      <td>transform</td>\n",
       "      <td>Negates a boolean value.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>76 rows  3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               name         type  \\\n",
       "0                               sum  aggregation   \n",
       "1                               std  aggregation   \n",
       "2                  avg_time_between  aggregation   \n",
       "3                             count  aggregation   \n",
       "4                            median  aggregation   \n",
       "5                      percent_true  aggregation   \n",
       "6                        num_unique  aggregation   \n",
       "7                             trend  aggregation   \n",
       "8                               min  aggregation   \n",
       "9                               all  aggregation   \n",
       "10                             mean  aggregation   \n",
       "11                             last  aggregation   \n",
       "12                             skew  aggregation   \n",
       "13                 time_since_first  aggregation   \n",
       "14                    n_most_common  aggregation   \n",
       "15                         num_true  aggregation   \n",
       "16                              max  aggregation   \n",
       "17                  time_since_last  aggregation   \n",
       "18                             mode  aggregation   \n",
       "19                              any  aggregation   \n",
       "20                            month    transform   \n",
       "21                   divide_numeric    transform   \n",
       "22                              and    transform   \n",
       "23                             diff    transform   \n",
       "24                            equal    transform   \n",
       "25                          is_null    transform   \n",
       "26                 multiply_numeric    transform   \n",
       "27               less_than_equal_to    transform   \n",
       "28                       days_since    transform   \n",
       "29            modulo_numeric_scalar    transform   \n",
       "..                              ...          ...   \n",
       "46                             year    transform   \n",
       "47                          cum_sum    transform   \n",
       "48              time_since_previous    transform   \n",
       "49                     equal_scalar    transform   \n",
       "50                           negate    transform   \n",
       "51                               or    transform   \n",
       "52                         absolute    transform   \n",
       "53          multiply_numeric_scalar    transform   \n",
       "54        less_than_equal_to_scalar    transform   \n",
       "55                             isin    transform   \n",
       "56                modulo_by_feature    transform   \n",
       "57  scalar_subtract_numeric_feature    transform   \n",
       "58                 less_than_scalar    transform   \n",
       "59                   modulo_numeric    transform   \n",
       "60                       time_since    transform   \n",
       "61                           minute    transform   \n",
       "62                 subtract_numeric    transform   \n",
       "63                        haversine    transform   \n",
       "64            divide_numeric_scalar    transform   \n",
       "65     greater_than_equal_to_scalar    transform   \n",
       "66                   num_characters    transform   \n",
       "67                          cum_min    transform   \n",
       "68                             hour    transform   \n",
       "69                      add_numeric    transform   \n",
       "70                         latitude    transform   \n",
       "71              greater_than_scalar    transform   \n",
       "72                       is_weekend    transform   \n",
       "73                        cum_count    transform   \n",
       "74                        not_equal    transform   \n",
       "75                              not    transform   \n",
       "\n",
       "                                          description  \n",
       "0      Calculates the total addition, ignoring `NaN`.  \n",
       "1   Computes the dispersion relative to the mean v...  \n",
       "2   Computes the average number of seconds between...  \n",
       "3   Determines the total number of values, excludi...  \n",
       "4   Determines the middlemost number in a list of ...  \n",
       "5            Determines the percent of `True` values.  \n",
       "6   Determines the number of distinct values, igno...  \n",
       "7       Calculates the trend of a variable over time.  \n",
       "8   Calculates the smallest value, ignoring `NaN` ...  \n",
       "9      Calculates if all values are 'True' in a list.  \n",
       "10         Computes the average for a list of values.  \n",
       "11               Determines the last value in a list.  \n",
       "12  Computes the extent to which a distribution di...  \n",
       "13  Calculates the time elapsed since the first da...  \n",
       "14           Determines the `n` most common elements.  \n",
       "15                Counts the number of `True` values.  \n",
       "16  Calculates the highest value, ignoring `NaN` v...  \n",
       "17  Calculates the time elapsed since the last dat...  \n",
       "18       Determines the most commonly repeated value.  \n",
       "19       Determines if any value is 'True' in a list.  \n",
       "20          Determines the month value of a datetime.  \n",
       "21                Element-wise division of two lists.  \n",
       "22             Element-wise logical AND of two lists.  \n",
       "23  Compute the difference between the value in a ...  \n",
       "24  Determines if values in one list are equal to ...  \n",
       "25                     Determines if a value is null.  \n",
       "26          Element-wise multiplication of two lists.  \n",
       "27  Determines if values in one list are less than...  \n",
       "28  Calculates the number of days from a value to ...  \n",
       "29  Return the modulo of each element in the list ...  \n",
       "..                                                ...  \n",
       "46           Determines the year value of a datetime.  \n",
       "47                     Calculates the cumulative sum.  \n",
       "48  Compute the time in seconds since the previous...  \n",
       "49  Determines if values in a list are equal to a ...  \n",
       "50                           Negates a numeric value.  \n",
       "51              Element-wise logical OR of two lists.  \n",
       "52           Computes the absolute value of a number.  \n",
       "53     Multiply each element in the list by a scalar.  \n",
       "54  Determines if values are less than or equal to...  \n",
       "55  Determines whether a value is present in a pro...  \n",
       "56  Return the modulo of a scalar by each element ...  \n",
       "57  Subtract each value in the list from a given s...  \n",
       "58  Determines if values are less than a given sca...  \n",
       "59                  Element-wise modulo of two lists.  \n",
       "60  Calculates time in nanoseconds from a value to...  \n",
       "61        Determines the minutes value of a datetime.  \n",
       "62             Element-wise subtraction of two lists.  \n",
       "63  Calculates the approximate haversine distance ...  \n",
       "64       Divide each element in the list by a scalar.  \n",
       "65  Determines if values are greater than or equal...  \n",
       "66   Calculates the number of characters in a string.  \n",
       "67                 Calculates the cumulative minimum.  \n",
       "68           Determines the hour value of a datetime.  \n",
       "69                Element-wise addition of two lists.  \n",
       "70  Returns the first tuple value in a list of Lat...  \n",
       "71  Determines if values are greater than a given ...  \n",
       "72           Determines if a date falls on a weekend.  \n",
       "73                   Calculates the cumulative count.  \n",
       "74  Determines if values in one list are not equal...  \n",
       "75                           Negates a boolean value.  \n",
       "\n",
       "[76 rows x 3 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ft.list_primitives()[0:90]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold\n",
    "def feature_selection(feature_matrix_train):\n",
    "    sel = VarianceThreshold(threshold=(.8 * (1 - .8)))\n",
    "    feature_matrix_train_array = sel.fit_transform(feature_matrix_train.fillna(0).values)\n",
    "    return feature_matrix_train_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model with and without new feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_columns = ['MSSubClass', 'OverallQual', 'OverallCond', 'LowQualFinSF', 'BsmtFullBath', 'BsmtHalfBath',\n",
    "                       'FullBath', 'HalfBath', 'BedroomAbvGr', 'KitchenAbvGr', 'TotRmsAbvGrd', 'Fireplaces',\n",
    "                       'GarageCars', '3SsnPorch', 'PoolArea', 'MiscVal', 'MoSold', 'YrSold']\n",
    "numerical_columns = ['Id', 'LotFrontage', 'LotArea', 'YearBuilt', 'YearRemodAdd', 'MasVnrArea', 'BsmtFinSF1',\n",
    "                         'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF', '1stFlrSF', '2ndFlrSF', 'GrLivArea', 'GarageYrBlt',\n",
    "                         'GarageArea', 'WoodDeckSF', 'OpenPorchSF', 'EnclosedPorch', 'ScreenPorch']\n",
    "all_columns = categorical_columns + numerical_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of features before feature selection (1460, 1998)\n",
      "size of features after feature selection (1460, 1882)\n",
      "alpha = 1 the current R2 = 80.858\n",
      "alpha = 2 the current R2 = 81.568\n",
      "alpha = 3 the current R2 = 82.04\n",
      "alpha = 4 the current R2 = 82.38\n",
      "alpha = 5 the current R2 = 82.638\n",
      "alpha = 6 the current R2 = 82.84\n",
      "alpha = 7 the current R2 = 83.002\n",
      "alpha = 8 the current R2 = 83.134\n",
      "alpha = 9 the current R2 = 83.245\n",
      "alpha = 10 the current R2 = 83.338\n",
      "alpha = 11 the current R2 = 83.419\n",
      "alpha = 12 the current R2 = 83.488\n",
      "alpha = 13 the current R2 = 83.549\n",
      "alpha = 14 the current R2 = 83.603\n",
      "alpha = 15 the current R2 = 83.651\n",
      "alpha = 16 the current R2 = 83.694\n",
      "alpha = 17 the current R2 = 83.733\n",
      "alpha = 18 the current R2 = 83.768\n",
      "alpha = 19 the current R2 = 83.8\n",
      "alpha = 20 the current R2 = 83.83\n",
      "alpha = 21 the current R2 = 83.857\n",
      "alpha = 22 the current R2 = 83.882\n",
      "alpha = 23 the current R2 = 83.905\n",
      "alpha = 24 the current R2 = 83.927\n",
      "alpha = 25 the current R2 = 83.947\n",
      "alpha = 26 the current R2 = 83.967\n",
      "alpha = 27 the current R2 = 83.984\n",
      "alpha = 28 the current R2 = 84.001\n",
      "alpha = 29 the current R2 = 84.017\n",
      "alpha = 30 the current R2 = 84.032\n",
      "alpha = 31 the current R2 = 84.046\n",
      "alpha = 32 the current R2 = 84.06\n",
      "alpha = 33 the current R2 = 84.073\n",
      "alpha = 34 the current R2 = 84.085\n",
      "alpha = 35 the current R2 = 84.097\n",
      "alpha = 36 the current R2 = 84.108\n",
      "alpha = 37 the current R2 = 84.119\n",
      "alpha = 38 the current R2 = 84.13\n",
      "alpha = 39 the current R2 = 84.14\n",
      "alpha = 40 the current R2 = 84.149\n",
      "alpha = 41 the current R2 = 84.159\n",
      "alpha = 42 the current R2 = 84.168\n",
      "alpha = 43 the current R2 = 84.176\n",
      "alpha = 44 the current R2 = 84.185\n",
      "alpha = 45 the current R2 = 84.193\n",
      "alpha = 46 the current R2 = 84.2\n",
      "alpha = 47 the current R2 = 84.208\n",
      "alpha = 48 the current R2 = 84.215\n",
      "alpha = 49 the current R2 = 84.223\n",
      "alpha = 50 the current R2 = 84.23\n",
      "alpha = 51 the current R2 = 84.236\n",
      "alpha = 52 the current R2 = 84.243\n",
      "alpha = 53 the current R2 = 84.249\n",
      "alpha = 54 the current R2 = 84.256\n",
      "alpha = 55 the current R2 = 84.262\n",
      "alpha = 56 the current R2 = 84.268\n",
      "alpha = 57 the current R2 = 84.274\n",
      "alpha = 58 the current R2 = 84.279\n",
      "alpha = 59 the current R2 = 84.285\n",
      "alpha = 60 the current R2 = 84.29\n",
      "alpha = 61 the current R2 = 84.296\n",
      "alpha = 62 the current R2 = 84.301\n",
      "alpha = 63 the current R2 = 84.306\n",
      "alpha = 64 the current R2 = 84.311\n",
      "alpha = 65 the current R2 = 84.316\n",
      "alpha = 66 the current R2 = 84.321\n",
      "alpha = 67 the current R2 = 84.325\n",
      "alpha = 68 the current R2 = 84.33\n",
      "alpha = 69 the current R2 = 84.335\n",
      "alpha = 70 the current R2 = 84.339\n",
      "alpha = 71 the current R2 = 84.343\n",
      "alpha = 72 the current R2 = 84.348\n",
      "alpha = 73 the current R2 = 84.352\n",
      "alpha = 74 the current R2 = 84.356\n",
      "alpha = 75 the current R2 = 84.36\n",
      "alpha = 76 the current R2 = 84.364\n",
      "alpha = 77 the current R2 = 84.368\n",
      "alpha = 78 the current R2 = 84.372\n",
      "alpha = 79 the current R2 = 84.376\n",
      "alpha = 80 the current R2 = 84.38\n",
      "alpha = 81 the current R2 = 84.384\n",
      "alpha = 82 the current R2 = 84.387\n",
      "alpha = 83 the current R2 = 84.391\n",
      "alpha = 84 the current R2 = 84.395\n",
      "alpha = 85 the current R2 = 84.398\n",
      "alpha = 86 the current R2 = 84.402\n",
      "alpha = 87 the current R2 = 84.405\n",
      "alpha = 88 the current R2 = 84.409\n",
      "alpha = 89 the current R2 = 84.412\n",
      "alpha = 90 the current R2 = 84.415\n",
      "alpha = 91 the current R2 = 84.419\n",
      "alpha = 92 the current R2 = 84.422\n",
      "alpha = 93 the current R2 = 84.425\n",
      "alpha = 94 the current R2 = 84.428\n",
      "alpha = 95 the current R2 = 84.431\n",
      "alpha = 96 the current R2 = 84.434\n",
      "alpha = 97 the current R2 = 84.437\n",
      "alpha = 98 the current R2 = 84.44\n",
      "alpha = 99 the current R2 = 84.443\n",
      "alpha = 100 the current R2 = 84.446\n",
      "alpha = 101 the current R2 = 84.449\n",
      "alpha = 102 the current R2 = 84.452\n",
      "alpha = 103 the current R2 = 84.455\n",
      "alpha = 104 the current R2 = 84.458\n",
      "alpha = 105 the current R2 = 84.461\n",
      "alpha = 106 the current R2 = 84.463\n",
      "alpha = 107 the current R2 = 84.466\n",
      "alpha = 108 the current R2 = 84.469\n",
      "alpha = 109 the current R2 = 84.471\n",
      "alpha = 110 the current R2 = 84.474\n",
      "alpha = 111 the current R2 = 84.477\n",
      "alpha = 112 the current R2 = 84.479\n",
      "alpha = 113 the current R2 = 84.482\n",
      "alpha = 114 the current R2 = 84.484\n",
      "alpha = 115 the current R2 = 84.487\n",
      "alpha = 116 the current R2 = 84.489\n",
      "alpha = 117 the current R2 = 84.492\n",
      "alpha = 118 the current R2 = 84.494\n",
      "alpha = 119 the current R2 = 84.497\n",
      "alpha = 120 the current R2 = 84.499\n",
      "alpha = 121 the current R2 = 84.502\n",
      "alpha = 122 the current R2 = 84.504\n",
      "alpha = 123 the current R2 = 84.506\n",
      "alpha = 124 the current R2 = 84.509\n",
      "alpha = 125 the current R2 = 84.511\n",
      "alpha = 126 the current R2 = 84.513\n",
      "alpha = 127 the current R2 = 84.515\n",
      "alpha = 128 the current R2 = 84.518\n",
      "alpha = 129 the current R2 = 84.52\n",
      "alpha = 130 the current R2 = 84.522\n",
      "alpha = 131 the current R2 = 84.524\n",
      "alpha = 132 the current R2 = 84.526\n",
      "alpha = 133 the current R2 = 84.528\n",
      "alpha = 134 the current R2 = 84.531\n",
      "alpha = 135 the current R2 = 84.533\n",
      "alpha = 136 the current R2 = 84.535\n",
      "alpha = 137 the current R2 = 84.537\n",
      "alpha = 138 the current R2 = 84.539\n",
      "alpha = 139 the current R2 = 84.541\n",
      "alpha = 140 the current R2 = 84.543\n",
      "alpha = 141 the current R2 = 84.545\n",
      "alpha = 142 the current R2 = 84.547\n",
      "alpha = 143 the current R2 = 84.549\n",
      "alpha = 144 the current R2 = 84.551\n",
      "alpha = 145 the current R2 = 84.553\n",
      "alpha = 146 the current R2 = 84.555\n",
      "alpha = 147 the current R2 = 84.556\n",
      "alpha = 148 the current R2 = 84.558\n",
      "alpha = 149 the current R2 = 84.56\n",
      "alpha = 150 the current R2 = 84.562\n",
      "alpha = 151 the current R2 = 84.564\n",
      "alpha = 152 the current R2 = 84.566\n",
      "alpha = 153 the current R2 = 84.567\n",
      "alpha = 154 the current R2 = 84.569\n",
      "alpha = 155 the current R2 = 84.571\n",
      "alpha = 156 the current R2 = 84.573\n",
      "alpha = 157 the current R2 = 84.575\n",
      "alpha = 158 the current R2 = 84.576\n",
      "alpha = 159 the current R2 = 84.578\n",
      "alpha = 160 the current R2 = 84.58\n",
      "alpha = 161 the current R2 = 84.581\n",
      "alpha = 162 the current R2 = 84.583\n",
      "alpha = 163 the current R2 = 84.585\n",
      "alpha = 164 the current R2 = 84.586\n",
      "alpha = 165 the current R2 = 84.588\n",
      "alpha = 166 the current R2 = 84.59\n",
      "alpha = 167 the current R2 = 84.591\n",
      "alpha = 168 the current R2 = 84.593\n",
      "alpha = 169 the current R2 = 84.595\n",
      "alpha = 170 the current R2 = 84.596\n",
      "alpha = 171 the current R2 = 84.598\n",
      "alpha = 172 the current R2 = 84.599\n",
      "alpha = 173 the current R2 = 84.601\n",
      "alpha = 174 the current R2 = 84.602\n",
      "alpha = 175 the current R2 = 84.604\n",
      "alpha = 176 the current R2 = 84.605\n",
      "alpha = 177 the current R2 = 84.607\n",
      "alpha = 178 the current R2 = 84.608\n",
      "alpha = 179 the current R2 = 84.61\n",
      "alpha = 180 the current R2 = 84.611\n",
      "alpha = 181 the current R2 = 84.613\n",
      "alpha = 182 the current R2 = 84.614\n",
      "alpha = 183 the current R2 = 84.616\n",
      "alpha = 184 the current R2 = 84.617\n",
      "alpha = 185 the current R2 = 84.618\n",
      "alpha = 186 the current R2 = 84.62\n",
      "alpha = 187 the current R2 = 84.621\n",
      "alpha = 188 the current R2 = 84.623\n",
      "alpha = 189 the current R2 = 84.624\n",
      "alpha = 190 the current R2 = 84.625\n",
      "alpha = 191 the current R2 = 84.627\n",
      "alpha = 192 the current R2 = 84.628\n",
      "alpha = 193 the current R2 = 84.629\n",
      "alpha = 194 the current R2 = 84.631\n",
      "alpha = 195 the current R2 = 84.632\n",
      "alpha = 196 the current R2 = 84.633\n",
      "alpha = 197 the current R2 = 84.635\n",
      "alpha = 198 the current R2 = 84.636\n",
      "alpha = 199 the current R2 = 84.637\n",
      "alpha = 200 the current R2 = 84.639\n",
      "alpha = 201 the current R2 = 84.64\n",
      "alpha = 202 the current R2 = 84.641\n",
      "alpha = 203 the current R2 = 84.642\n",
      "alpha = 204 the current R2 = 84.644\n",
      "alpha = 205 the current R2 = 84.645\n",
      "alpha = 206 the current R2 = 84.646\n",
      "alpha = 207 the current R2 = 84.647\n",
      "alpha = 208 the current R2 = 84.648\n",
      "alpha = 209 the current R2 = 84.65\n",
      "alpha = 210 the current R2 = 84.651\n",
      "alpha = 211 the current R2 = 84.652\n",
      "alpha = 212 the current R2 = 84.653\n",
      "alpha = 213 the current R2 = 84.654\n",
      "alpha = 214 the current R2 = 84.655\n",
      "alpha = 215 the current R2 = 84.656\n",
      "alpha = 216 the current R2 = 84.658\n",
      "alpha = 217 the current R2 = 84.659\n",
      "alpha = 218 the current R2 = 84.66\n",
      "alpha = 219 the current R2 = 84.661\n",
      "alpha = 220 the current R2 = 84.662\n",
      "alpha = 221 the current R2 = 84.663\n",
      "alpha = 222 the current R2 = 84.664\n",
      "alpha = 223 the current R2 = 84.665\n",
      "alpha = 224 the current R2 = 84.666\n",
      "alpha = 225 the current R2 = 84.667\n",
      "alpha = 226 the current R2 = 84.668\n",
      "alpha = 227 the current R2 = 84.67\n",
      "alpha = 228 the current R2 = 84.671\n",
      "alpha = 229 the current R2 = 84.672\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha = 230 the current R2 = 84.673\n",
      "alpha = 231 the current R2 = 84.674\n",
      "alpha = 232 the current R2 = 84.675\n",
      "alpha = 233 the current R2 = 84.676\n",
      "alpha = 234 the current R2 = 84.677\n",
      "alpha = 235 the current R2 = 84.678\n",
      "alpha = 236 the current R2 = 84.679\n",
      "alpha = 237 the current R2 = 84.68\n",
      "alpha = 238 the current R2 = 84.681\n",
      "alpha = 239 the current R2 = 84.681\n",
      "alpha = 240 the current R2 = 84.682\n",
      "alpha = 241 the current R2 = 84.683\n",
      "alpha = 242 the current R2 = 84.684\n",
      "alpha = 243 the current R2 = 84.685\n",
      "alpha = 244 the current R2 = 84.686\n",
      "alpha = 245 the current R2 = 84.687\n",
      "alpha = 246 the current R2 = 84.688\n",
      "alpha = 247 the current R2 = 84.689\n",
      "alpha = 248 the current R2 = 84.69\n",
      "alpha = 249 the current R2 = 84.691\n",
      "alpha = 250 the current R2 = 84.692\n",
      "alpha = 251 the current R2 = 84.692\n",
      "alpha = 252 the current R2 = 84.693\n",
      "alpha = 253 the current R2 = 84.694\n",
      "alpha = 254 the current R2 = 84.695\n",
      "alpha = 255 the current R2 = 84.696\n",
      "alpha = 256 the current R2 = 84.697\n",
      "alpha = 257 the current R2 = 84.698\n",
      "alpha = 258 the current R2 = 84.698\n",
      "alpha = 259 the current R2 = 84.699\n",
      "alpha = 260 the current R2 = 84.7\n",
      "alpha = 261 the current R2 = 84.701\n",
      "alpha = 262 the current R2 = 84.702\n",
      "alpha = 263 the current R2 = 84.702\n",
      "alpha = 264 the current R2 = 84.703\n",
      "alpha = 265 the current R2 = 84.704\n",
      "alpha = 266 the current R2 = 84.705\n",
      "alpha = 267 the current R2 = 84.706\n",
      "alpha = 268 the current R2 = 84.706\n",
      "alpha = 269 the current R2 = 84.707\n",
      "alpha = 270 the current R2 = 84.708\n",
      "alpha = 271 the current R2 = 84.709\n",
      "alpha = 272 the current R2 = 84.709\n",
      "alpha = 273 the current R2 = 84.71\n",
      "alpha = 274 the current R2 = 84.711\n",
      "alpha = 275 the current R2 = 84.712\n",
      "alpha = 276 the current R2 = 84.712\n",
      "alpha = 277 the current R2 = 84.713\n",
      "alpha = 278 the current R2 = 84.714\n",
      "alpha = 279 the current R2 = 84.715\n",
      "alpha = 280 the current R2 = 84.715\n",
      "alpha = 281 the current R2 = 84.716\n",
      "alpha = 282 the current R2 = 84.717\n",
      "alpha = 283 the current R2 = 84.717\n",
      "alpha = 284 the current R2 = 84.718\n",
      "alpha = 285 the current R2 = 84.719\n",
      "alpha = 286 the current R2 = 84.719\n",
      "alpha = 287 the current R2 = 84.72\n",
      "alpha = 288 the current R2 = 84.721\n",
      "alpha = 289 the current R2 = 84.721\n",
      "alpha = 290 the current R2 = 84.722\n",
      "alpha = 291 the current R2 = 84.723\n",
      "alpha = 292 the current R2 = 84.723\n",
      "alpha = 293 the current R2 = 84.724\n",
      "alpha = 294 the current R2 = 84.725\n",
      "alpha = 295 the current R2 = 84.725\n",
      "alpha = 296 the current R2 = 84.726\n",
      "alpha = 297 the current R2 = 84.727\n",
      "alpha = 298 the current R2 = 84.727\n",
      "alpha = 299 the current R2 = 84.728\n",
      "alpha = 300 the current R2 = 84.728\n",
      "alpha = 301 the current R2 = 84.729\n",
      "alpha = 302 the current R2 = 84.73\n",
      "alpha = 303 the current R2 = 84.73\n",
      "alpha = 304 the current R2 = 84.731\n",
      "alpha = 305 the current R2 = 84.731\n",
      "alpha = 306 the current R2 = 84.732\n",
      "alpha = 307 the current R2 = 84.732\n",
      "alpha = 308 the current R2 = 84.733\n",
      "alpha = 309 the current R2 = 84.734\n",
      "alpha = 310 the current R2 = 84.734\n",
      "alpha = 311 the current R2 = 84.735\n",
      "alpha = 312 the current R2 = 84.735\n",
      "alpha = 313 the current R2 = 84.736\n",
      "alpha = 314 the current R2 = 84.736\n",
      "alpha = 315 the current R2 = 84.737\n",
      "alpha = 316 the current R2 = 84.737\n",
      "alpha = 317 the current R2 = 84.738\n",
      "alpha = 318 the current R2 = 84.739\n",
      "alpha = 319 the current R2 = 84.739\n",
      "alpha = 320 the current R2 = 84.74\n",
      "alpha = 321 the current R2 = 84.74\n",
      "alpha = 322 the current R2 = 84.741\n",
      "alpha = 323 the current R2 = 84.741\n",
      "alpha = 324 the current R2 = 84.742\n",
      "alpha = 325 the current R2 = 84.742\n",
      "alpha = 326 the current R2 = 84.743\n",
      "alpha = 327 the current R2 = 84.743\n",
      "alpha = 328 the current R2 = 84.744\n",
      "alpha = 329 the current R2 = 84.744\n",
      "alpha = 330 the current R2 = 84.744\n",
      "alpha = 331 the current R2 = 84.745\n",
      "alpha = 332 the current R2 = 84.745\n",
      "alpha = 333 the current R2 = 84.746\n",
      "alpha = 334 the current R2 = 84.746\n",
      "alpha = 335 the current R2 = 84.747\n",
      "alpha = 336 the current R2 = 84.747\n",
      "alpha = 337 the current R2 = 84.748\n",
      "alpha = 338 the current R2 = 84.748\n",
      "alpha = 339 the current R2 = 84.749\n",
      "alpha = 340 the current R2 = 84.749\n",
      "alpha = 341 the current R2 = 84.749\n",
      "alpha = 342 the current R2 = 84.75\n",
      "alpha = 343 the current R2 = 84.75\n",
      "alpha = 344 the current R2 = 84.751\n",
      "alpha = 345 the current R2 = 84.751\n",
      "alpha = 346 the current R2 = 84.752\n",
      "alpha = 347 the current R2 = 84.752\n",
      "alpha = 348 the current R2 = 84.752\n",
      "alpha = 349 the current R2 = 84.753\n",
      "alpha = 350 the current R2 = 84.753\n",
      "alpha = 351 the current R2 = 84.754\n",
      "alpha = 352 the current R2 = 84.754\n",
      "alpha = 353 the current R2 = 84.754\n",
      "alpha = 354 the current R2 = 84.755\n",
      "alpha = 355 the current R2 = 84.755\n",
      "alpha = 356 the current R2 = 84.756\n",
      "alpha = 357 the current R2 = 84.756\n",
      "alpha = 358 the current R2 = 84.756\n",
      "alpha = 359 the current R2 = 84.757\n",
      "alpha = 360 the current R2 = 84.757\n",
      "alpha = 361 the current R2 = 84.757\n",
      "alpha = 362 the current R2 = 84.758\n",
      "alpha = 363 the current R2 = 84.758\n",
      "alpha = 364 the current R2 = 84.758\n",
      "alpha = 365 the current R2 = 84.759\n",
      "alpha = 366 the current R2 = 84.759\n",
      "alpha = 367 the current R2 = 84.76\n",
      "alpha = 368 the current R2 = 84.76\n",
      "alpha = 369 the current R2 = 84.76\n",
      "alpha = 370 the current R2 = 84.761\n",
      "alpha = 371 the current R2 = 84.761\n",
      "alpha = 372 the current R2 = 84.761\n",
      "alpha = 373 the current R2 = 84.762\n",
      "alpha = 374 the current R2 = 84.762\n",
      "alpha = 375 the current R2 = 84.762\n",
      "alpha = 376 the current R2 = 84.762\n",
      "alpha = 377 the current R2 = 84.763\n",
      "alpha = 378 the current R2 = 84.763\n",
      "alpha = 379 the current R2 = 84.763\n",
      "alpha = 380 the current R2 = 84.764\n",
      "alpha = 381 the current R2 = 84.764\n",
      "alpha = 382 the current R2 = 84.764\n",
      "alpha = 383 the current R2 = 84.765\n",
      "alpha = 384 the current R2 = 84.765\n",
      "alpha = 385 the current R2 = 84.765\n",
      "alpha = 386 the current R2 = 84.765\n",
      "alpha = 387 the current R2 = 84.766\n",
      "alpha = 388 the current R2 = 84.766\n",
      "alpha = 389 the current R2 = 84.766\n",
      "alpha = 390 the current R2 = 84.767\n",
      "alpha = 391 the current R2 = 84.767\n",
      "alpha = 392 the current R2 = 84.767\n",
      "alpha = 393 the current R2 = 84.767\n",
      "alpha = 394 the current R2 = 84.768\n",
      "alpha = 395 the current R2 = 84.768\n",
      "alpha = 396 the current R2 = 84.768\n",
      "alpha = 397 the current R2 = 84.768\n",
      "alpha = 398 the current R2 = 84.769\n",
      "alpha = 399 the current R2 = 84.769\n",
      "alpha = 400 the current R2 = 84.769\n",
      "alpha = 401 the current R2 = 84.769\n",
      "alpha = 402 the current R2 = 84.77\n",
      "alpha = 403 the current R2 = 84.77\n",
      "alpha = 404 the current R2 = 84.77\n",
      "alpha = 405 the current R2 = 84.77\n",
      "alpha = 406 the current R2 = 84.771\n",
      "alpha = 407 the current R2 = 84.771\n",
      "alpha = 408 the current R2 = 84.771\n",
      "alpha = 409 the current R2 = 84.771\n",
      "alpha = 410 the current R2 = 84.771\n",
      "alpha = 411 the current R2 = 84.772\n",
      "alpha = 412 the current R2 = 84.772\n",
      "alpha = 413 the current R2 = 84.772\n",
      "alpha = 414 the current R2 = 84.772\n",
      "alpha = 415 the current R2 = 84.772\n",
      "alpha = 416 the current R2 = 84.773\n",
      "alpha = 417 the current R2 = 84.773\n",
      "alpha = 418 the current R2 = 84.773\n",
      "alpha = 419 the current R2 = 84.773\n",
      "alpha = 420 the current R2 = 84.773\n",
      "alpha = 421 the current R2 = 84.774\n",
      "alpha = 422 the current R2 = 84.774\n",
      "alpha = 423 the current R2 = 84.774\n",
      "alpha = 424 the current R2 = 84.774\n",
      "alpha = 425 the current R2 = 84.774\n",
      "alpha = 426 the current R2 = 84.775\n",
      "alpha = 427 the current R2 = 84.775\n",
      "alpha = 428 the current R2 = 84.775\n",
      "alpha = 429 the current R2 = 84.775\n",
      "alpha = 430 the current R2 = 84.775\n",
      "alpha = 431 the current R2 = 84.775\n",
      "alpha = 432 the current R2 = 84.776\n",
      "alpha = 433 the current R2 = 84.776\n",
      "alpha = 434 the current R2 = 84.776\n",
      "alpha = 435 the current R2 = 84.776\n",
      "alpha = 436 the current R2 = 84.776\n",
      "alpha = 437 the current R2 = 84.776\n",
      "alpha = 438 the current R2 = 84.777\n",
      "alpha = 439 the current R2 = 84.777\n",
      "alpha = 440 the current R2 = 84.777\n",
      "alpha = 441 the current R2 = 84.777\n",
      "alpha = 442 the current R2 = 84.777\n",
      "alpha = 443 the current R2 = 84.777\n",
      "alpha = 444 the current R2 = 84.777\n",
      "alpha = 445 the current R2 = 84.777\n",
      "alpha = 446 the current R2 = 84.778\n",
      "alpha = 447 the current R2 = 84.778\n",
      "alpha = 448 the current R2 = 84.778\n",
      "alpha = 449 the current R2 = 84.778\n",
      "alpha = 450 the current R2 = 84.778\n",
      "alpha = 451 the current R2 = 84.778\n",
      "alpha = 452 the current R2 = 84.778\n",
      "alpha = 453 the current R2 = 84.778\n",
      "alpha = 454 the current R2 = 84.779\n",
      "alpha = 455 the current R2 = 84.779\n",
      "alpha = 456 the current R2 = 84.779\n",
      "alpha = 457 the current R2 = 84.779\n",
      "alpha = 458 the current R2 = 84.779\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha = 459 the current R2 = 84.779\n",
      "alpha = 460 the current R2 = 84.779\n",
      "alpha = 461 the current R2 = 84.779\n",
      "alpha = 462 the current R2 = 84.779\n",
      "alpha = 463 the current R2 = 84.78\n",
      "alpha = 464 the current R2 = 84.78\n",
      "alpha = 465 the current R2 = 84.78\n",
      "alpha = 466 the current R2 = 84.78\n",
      "alpha = 467 the current R2 = 84.78\n",
      "alpha = 468 the current R2 = 84.78\n",
      "alpha = 469 the current R2 = 84.78\n",
      "alpha = 470 the current R2 = 84.78\n",
      "alpha = 471 the current R2 = 84.78\n",
      "alpha = 472 the current R2 = 84.78\n",
      "alpha = 473 the current R2 = 84.78\n",
      "alpha = 474 the current R2 = 84.78\n",
      "alpha = 475 the current R2 = 84.781\n",
      "alpha = 476 the current R2 = 84.781\n",
      "alpha = 477 the current R2 = 84.781\n",
      "alpha = 478 the current R2 = 84.781\n",
      "alpha = 479 the current R2 = 84.781\n",
      "alpha = 480 the current R2 = 84.781\n",
      "alpha = 481 the current R2 = 84.781\n",
      "alpha = 482 the current R2 = 84.781\n",
      "alpha = 483 the current R2 = 84.781\n",
      "alpha = 484 the current R2 = 84.781\n",
      "alpha = 485 the current R2 = 84.781\n",
      "alpha = 486 the current R2 = 84.781\n",
      "alpha = 487 the current R2 = 84.781\n",
      "alpha = 488 the current R2 = 84.781\n",
      "alpha = 489 the current R2 = 84.781\n",
      "alpha = 490 the current R2 = 84.781\n",
      "alpha = 491 the current R2 = 84.781\n",
      "alpha = 492 the current R2 = 84.782\n",
      "alpha = 493 the current R2 = 84.782\n",
      "alpha = 494 the current R2 = 84.782\n",
      "alpha = 495 the current R2 = 84.782\n",
      "alpha = 496 the current R2 = 84.782\n",
      "alpha = 497 the current R2 = 84.782\n",
      "alpha = 498 the current R2 = 84.782\n",
      "alpha = 499 the current R2 = 84.782\n",
      "alpha = 500 the current R2 = 84.782\n",
      "alpha = 501 the current R2 = 84.782\n",
      "alpha = 502 the current R2 = 84.782\n",
      "alpha = 503 the current R2 = 84.782\n",
      "alpha = 504 the current R2 = 84.782\n",
      "alpha = 505 the current R2 = 84.782\n",
      "alpha = 506 the current R2 = 84.782\n",
      "alpha = 507 the current R2 = 84.782\n",
      "alpha = 508 the current R2 = 84.782\n",
      "alpha = 509 the current R2 = 84.782\n",
      "alpha = 510 the current R2 = 84.782\n",
      "alpha = 511 the current R2 = 84.782\n",
      "alpha = 512 the current R2 = 84.782\n",
      "alpha = 513 the current R2 = 84.782\n",
      "alpha = 514 the current R2 = 84.782\n",
      "alpha = 515 the current R2 = 84.782\n",
      "alpha = 516 the current R2 = 84.782\n",
      "alpha = 517 the current R2 = 84.782\n",
      "alpha = 518 the current R2 = 84.782\n",
      "CPU times: user 12min 56s, sys: 58.8 s, total: 13min 54s\n",
      "Wall time: 7min 1s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import KFold\n",
    "best_score = 0.77\n",
    "\n",
    "y_train = np.array(train_target)\n",
    "\n",
    "#X_train_df = train_dataframe[numerical_columns] # numeric features (baseline model) 77\n",
    "#X_train_df = train_dataframe[categorical_columns] # categorical features 81.5\n",
    "#X_train_df = train_dataframe[all_columns] # both numerical and categorical features\n",
    "X_train_df = feature_matrix_train.fillna(0) # Featuretool features\n",
    "\n",
    "# normalize data again\n",
    "X_train_df = standard_scale_nuermical_features(X_train_df)\n",
    "\n",
    "print(\"size of features before feature selection\", X_train_df.shape)\n",
    "# apply feature selection\n",
    "X_train_df = feature_selection(X_train_df)\n",
    "print(\"size of features after feature selection\", X_train_df.shape)\n",
    "\n",
    "train_array = X_train_df\n",
    "\n",
    "for regul in range(1,1000):\n",
    "    linear_regression_model = linear_model.Ridge(alpha=regul)\n",
    "\n",
    "    predictions = 0\n",
    "    n_fold = 5  # number of folds\n",
    "    kfold = KFold(n_splits=n_fold, shuffle=True, random_state=1)\n",
    "\n",
    "    fold_nr = 0  # counter for identifying models\n",
    "    r2_linear = 0\n",
    "\n",
    "    for train, test in kfold.split(train_array):\n",
    "        fold_nr += 1\n",
    "        #print(\"foldnr.\", fold_nr)\n",
    "        linear_regression_model.fit(train_array[train], y_train[train])\n",
    "\n",
    "        y_pred_linear = linear_regression_model.predict(train_array[test])\n",
    "\n",
    "        #print(\"Mean squared error linear: %.2f\"\n",
    "         #     % mean_squared_error(y_train[test], y_pred_linear))\n",
    "\n",
    "        #print('R2 linear: %.2f' % r2_score(y_train[test], y_pred_linear))\n",
    "\n",
    "        r2_linear += r2_score(y_train[test], y_pred_linear)\n",
    "\n",
    "    # mean R2\n",
    "    #print(r2_linear/n_fold)\n",
    "    if r2_linear/n_fold > best_score:\n",
    "        best_score = r2_linear/n_fold\n",
    "        print(f\"alpha = {regul}\",f\"the current R2 = {round(100*best_score,3)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature transformation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(range(1,1001))\n",
    "y = np.log(X) + np.random.randn(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000,)\n",
      "(1000,)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the correlation between the feature x and the target y -> 0.5972085998953457\n"
     ]
    }
   ],
   "source": [
    "print(\"the correlation between the feature x and the target y ->\", np.corrcoef(X,y)[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "matplotlib.style.use('ggplot')\n",
    "\n",
    "plt.scatter(X, y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original-> 0.5972085998953457\n",
      "log-> 0.6870000635729883\n",
      "X**2-> 0.5142824686285609\n",
      "X**3-> 0.45662166005315064\n",
      "X**4-> 0.4144113021253784\n",
      "X**0.5-> 0.64941480886364\n",
      "X**0.25-> 0.6738098603108392\n",
      "X**0.05 -> 0.6860487733550451\n",
      "X**0.005 -> 0.6869568851704839\n"
     ]
    }
   ],
   "source": [
    "print(\"original->\", np.corrcoef(X,y)[0][1])\n",
    "print(\"log->\",np.corrcoef(np.log(X),y)[0][1])\n",
    "print(\"X**2->\", np.corrcoef(X**2,y)[0][1])\n",
    "print(\"X**3->\", np.corrcoef(X**3,y)[0][1])\n",
    "print(\"X**4->\", np.corrcoef(X**4,y)[0][1])\n",
    "print(\"X**0.5->\",np.corrcoef(X**0.5,y)[0][1])\n",
    "print(\"X**0.25->\",np.corrcoef(X**0.25,y)[0][1])\n",
    "print(\"X**0.05 ->\",np.corrcoef(X**0.05,y)[0][1])\n",
    "print(\"X**0.005 ->\",np.corrcoef(X**0.005,y)[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "matplotlib.style.use('ggplot')\n",
    "\n",
    "plt.scatter(X**0.05, y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"latex_300.png\">\n",
    "<img src=\"latex_log.png\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_transformation(dataframe, train_target):\n",
    "    \"\"\"\n",
    "    Apply transformation on features and calculate the correlation with the target\n",
    "    :param dataframe: pandas dataframe\n",
    "    :param train_target: pandas series\n",
    "    :return: pandas dataframe contains the correlation between each feature and the target for different\n",
    "     applied transformations\n",
    "    \"\"\"\n",
    "    # remove negative values and zeros to avoid math problem\n",
    "    for col_i in dataframe.columns:\n",
    "        dataframe[col_i] += abs(min(dataframe[col_i])) + 1\n",
    "\n",
    "    # 1 means the original values. If the type is number, it means x^number\n",
    "    transformation_type = [1, \"log\", 0.25, 0.5, 0.75, 2, 3, 4]\n",
    "    correlation_dataframe = pd.DataFrame(columns=[str(x) for x in transformation_type])\n",
    "\n",
    "    for trans_i in transformation_type:\n",
    "        if trans_i == \"log\":\n",
    "            print(\"Appying the log transformation to the given dataset\")\n",
    "            dataframe_trans = np.log(dataframe)\n",
    "        else:\n",
    "            if trans_i != 1:\n",
    "                print(\"Appying the x**{} transformation to the given dataset\".format(trans_i))\n",
    "            dataframe_trans = (dataframe) ** trans_i\n",
    "\n",
    "        correlation_dataframe[str(trans_i)] = [round(np.corrcoef([dataframe_trans[x], train_target])[0][1], 2)\n",
    "                                          for x in dataframe.columns]\n",
    "\n",
    "        correlation_dataframe.index = dataframe.columns\n",
    "    return correlation_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appying the log transformation to the given dataset\n",
      "Appying the x**0.25 transformation to the given dataset\n",
      "Appying the x**0.5 transformation to the given dataset\n",
      "Appying the x**0.75 transformation to the given dataset\n",
      "Appying the x**2 transformation to the given dataset\n",
      "Appying the x**3 transformation to the given dataset\n",
      "Appying the x**4 transformation to the given dataset\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>log</th>\n",
       "      <th>0.25</th>\n",
       "      <th>0.5</th>\n",
       "      <th>0.75</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LotFrontage</th>\n",
       "      <td>0.34</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LotArea</th>\n",
       "      <td>0.26</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YearBuilt</th>\n",
       "      <td>0.59</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YearRemodAdd</th>\n",
       "      <td>0.57</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MasVnrArea</th>\n",
       "      <td>0.43</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <td>0.37</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BsmtFinSF2</th>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BsmtUnfSF</th>\n",
       "      <td>0.22</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TotalBsmtSF</th>\n",
       "      <td>0.61</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1stFlrSF</th>\n",
       "      <td>0.60</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2ndFlrSF</th>\n",
       "      <td>0.32</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GrLivArea</th>\n",
       "      <td>0.70</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GarageYrBlt</th>\n",
       "      <td>0.50</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GarageArea</th>\n",
       "      <td>0.65</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WoodDeckSF</th>\n",
       "      <td>0.33</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OpenPorchSF</th>\n",
       "      <td>0.32</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EnclosedPorch</th>\n",
       "      <td>-0.15</td>\n",
       "      <td>-0.18</td>\n",
       "      <td>-0.18</td>\n",
       "      <td>-0.17</td>\n",
       "      <td>-0.16</td>\n",
       "      <td>-0.10</td>\n",
       "      <td>-0.05</td>\n",
       "      <td>-0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ScreenPorch</th>\n",
       "      <td>0.12</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  1   log  0.25   0.5  0.75     2     3     4\n",
       "LotFrontage    0.34  0.35  0.35  0.35  0.35  0.24  0.13  0.06\n",
       "LotArea        0.26  0.39  0.37  0.34  0.30  0.12  0.08  0.07\n",
       "YearBuilt      0.59  0.53  0.55  0.56  0.58  0.61  0.63  0.63\n",
       "YearRemodAdd   0.57  0.56  0.56  0.56  0.57  0.56  0.55  0.54\n",
       "MasVnrArea     0.43  0.44  0.44  0.44  0.44  0.36  0.27  0.19\n",
       "BsmtFinSF1     0.37  0.33  0.34  0.35  0.37  0.31  0.13  0.04\n",
       "BsmtFinSF2     0.00 -0.02 -0.01 -0.01 -0.00  0.03  0.05  0.06\n",
       "BsmtUnfSF      0.22  0.20  0.20  0.21  0.22  0.24  0.26  0.26\n",
       "TotalBsmtSF    0.61  0.60  0.61  0.62  0.62  0.50  0.28  0.12\n",
       "1stFlrSF       0.60  0.61  0.61  0.61  0.60  0.52  0.37  0.20\n",
       "2ndFlrSF       0.32  0.26  0.28  0.29  0.31  0.37  0.40  0.40\n",
       "GrLivArea      0.70  0.73  0.73  0.72  0.71  0.62  0.47  0.32\n",
       "GarageYrBlt    0.50  0.45  0.46  0.48  0.49  0.53  0.55  0.56\n",
       "GarageArea     0.65  0.62  0.64  0.65  0.65  0.62  0.55  0.46\n",
       "WoodDeckSF     0.33  0.36  0.35  0.35  0.34  0.28  0.21  0.16\n",
       "OpenPorchSF    0.32  0.41  0.39  0.37  0.35  0.20  0.10  0.04\n",
       "EnclosedPorch -0.15 -0.18 -0.18 -0.17 -0.16 -0.10 -0.05 -0.01\n",
       "ScreenPorch    0.12  0.11  0.12  0.12  0.12  0.12  0.11  0.10"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "apply_transformation(train_dataframe[numerical], train_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of features before feature selection (1460, 37)\n",
      "size of features after feature selection (1460, 37)\n",
      "mean R2 5 Folds:  85.85 alpha = 1\n",
      "mean MSE 5 Folds:  0.0229\n",
      "mean R2 5 Folds:  85.86 alpha = 2\n",
      "mean MSE 5 Folds:  0.0229\n",
      "mean R2 5 Folds:  85.86 alpha = 3\n",
      "mean MSE 5 Folds:  0.0228\n",
      "mean R2 5 Folds:  85.87 alpha = 4\n",
      "mean MSE 5 Folds:  0.0228\n",
      "mean R2 5 Folds:  85.88 alpha = 5\n",
      "mean MSE 5 Folds:  0.0228\n",
      "mean R2 5 Folds:  85.88 alpha = 6\n",
      "mean MSE 5 Folds:  0.0228\n",
      "mean R2 5 Folds:  85.88 alpha = 7\n",
      "mean MSE 5 Folds:  0.0228\n",
      "mean R2 5 Folds:  85.88 alpha = 8\n",
      "mean MSE 5 Folds:  0.0228\n",
      "mean R2 5 Folds:  85.88 alpha = 9\n",
      "mean MSE 5 Folds:  0.0228\n",
      "mean R2 5 Folds:  85.89 alpha = 10\n",
      "mean MSE 5 Folds:  0.0228\n",
      "mean R2 5 Folds:  85.89 alpha = 11\n",
      "mean MSE 5 Folds:  0.0228\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "\n",
    "train_dataframe_ = train_dataframe[all_columns]\n",
    "\n",
    "#+\n",
    "train_dataframe_[\"LotArea\"] = np.log(train_dataframe[\"LotArea\"] + abs(min(train_dataframe[\"LotArea\"])) + 1)\n",
    "#+\n",
    "train_dataframe_[\"YearBuilt\"] = (train_dataframe[\"YearBuilt\"] + abs(min(train_dataframe[\"YearBuilt\"])) + 1)**2\n",
    "#-\n",
    "#train_dataframe_[\"BsmtFinSF2\"] = (train_dataframe[\"BsmtFinSF2\"] + abs(min(train_dataframe[\"BsmtFinSF2\"])) + 1)**4\n",
    "#train_dataframe_[\"BsmtUnfSF\"] = (train_dataframe[\"BsmtUnfSF\"] + abs(min(train_dataframe[\"BsmtUnfSF\"])) + 1)**3\n",
    "#train_dataframe_[\"2ndFlrSF\"] = (train_dataframe[\"2ndFlrSF\"] + abs(min(train_dataframe[\"2ndFlrSF\"])) + 1)**3\n",
    "\n",
    "#+\n",
    "train_dataframe_[\"GrLivArea\"] = np.log(train_dataframe[\"GrLivArea\"] + abs(min(train_dataframe[\"GrLivArea\"])) + 1)\n",
    "\n",
    "#-\n",
    "# train_dataframe_[\"GarageYrBlt\"] = (train_dataframe[\"GarageYrBlt\"] + abs(min(train_dataframe[\"GarageYrBlt\"])) + 1)**4\n",
    "\n",
    "#+\n",
    "train_dataframe_[\"WoodDeckSF\"] = np.log(train_dataframe[\"WoodDeckSF\"] + abs(min(train_dataframe[\"WoodDeckSF\"])) + 1)\n",
    "train_dataframe_[\"OpenPorchSF\"] = np.log(train_dataframe[\"OpenPorchSF\"] + abs(min(train_dataframe[\"OpenPorchSF\"])) + 1)\n",
    "\n",
    "#-\n",
    "#train_dataframe_[\"EnclosedPorch\"] = np.log(train_dataframe[\"EnclosedPorch\"] + abs(min(train_dataframe[\"EnclosedPorch\"])) + 1)\n",
    "\n",
    "train_dataframe_ = standard_scale_nuermical_features(train_dataframe_)\n",
    "\n",
    "train_array = train_dataframe_\n",
    "print(\"size of features before feature selection\", train_array.shape)\n",
    "# apply feature selection\n",
    "train_array = feature_selection(train_array)\n",
    "print(\"size of features after feature selection\", train_array.shape)\n",
    "\n",
    "\n",
    "y_train = np.array(train_target)\n",
    "\n",
    "\n",
    "\n",
    "predictions = 0\n",
    "n_fold = 5  # number of folds\n",
    "kfold = KFold(n_splits=n_fold, shuffle=True, random_state=1)\n",
    "best_score = 0.77\n",
    "\n",
    "for regul in range(1,2000):\n",
    "    linear_regression_model = linear_model.Ridge(alpha=regul)\n",
    "        \n",
    "    fold_nr = 0  # counter for identifying models\n",
    "    r2_linear = 0\n",
    "    mse = 0\n",
    "\n",
    "    for train, test in kfold.split(train_array):\n",
    "        fold_nr += 1\n",
    "        #print(\"foldnr.\", fold_nr)\n",
    "        linear_regression_model.fit(train_array[train], y_train[train])\n",
    "\n",
    "        y_pred_linear = linear_regression_model.predict(train_array[test])\n",
    "\n",
    "        #print(\"Mean squared error linear: %.4f\"\n",
    "        #      % mean_squared_error(y_train[test], y_pred_linear))\n",
    "\n",
    "        #print('R2 linear: %.1f' % round(100*r2_score(y_train[test], y_pred_linear),1))\n",
    "\n",
    "        r2_linear += r2_score(y_train[test], y_pred_linear)\n",
    "        mse += mean_squared_error(y_train[test], y_pred_linear)\n",
    "\n",
    "    # mean R2\n",
    "    if r2_linear/n_fold > best_score:\n",
    "        best_score = r2_linear/n_fold\n",
    "        print(\"mean R2 5 Folds: \", round(100*r2_linear/n_fold,2), f\"alpha = {regul}\")\n",
    "        print(\"mean MSE 5 Folds: \", round(mse/n_fold,4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Mapping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "linear model <br>\n",
    "<img src=\"latex_linear_model.png\">\n",
    "After mapping features <br>\n",
    "<img src=\"latex_linear_model_mapping_features.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def features_mapping(numpy_array, map_degree=2, terms_mix_degree=2, features_numbers_list=[]):\n",
    "    \"\"\"\n",
    "    this function introduces the possible nonlinearity and dependency between the independent features. For example\n",
    "    if we have 2 features x1 and x2, after applying the function, we get the following features if the map_degree = 2\n",
    "    x1, x2, x1^2, x2^2, x1*x2\n",
    "    it is important to apply the map_features_test function after applying this function to be sure that the test data\n",
    "    are mapped exactly as the train datasets\n",
    "    :param numpy_array: numpy arrary with size (nxm) where n is the number of rows and m is the number of the features\n",
    "    :param map_degree: the nonlinearity degree. For example map_degree = 2 --> x and x^2 will be considered. If\n",
    "     map_degree = 3 --> x, x^2 and x^3 will be considered. If 0 is passed, this type of nonlinearity will be not\n",
    "     considered\n",
    "    :param terms_mix_degree: the degree of the introduced dependency between features.\n",
    "    For example, if mix_degree = 2 --> x1, x2, x3, x1*x2 x1*x3 and x2*x3 will be considered.\n",
    "     If mix_degree = 3 -> x1, x2, x3, x1*x2 x1*x3, x2*x3, x1*x2*x3. If 0 is passed, this type of nonlinearity will not\n",
    "     be considered\n",
    "    :param features_numbers_list: list of integers that represents the features that should be considered by applying\n",
    "    this function. if not passed, all features will be considered. For example, if there is 3 features x1, x2, x3 which\n",
    "     has the following order indexes [0, 1, 2] in dataframe, and features_numbers_list = [1, 2] are passed, then only\n",
    "     x2 and x3 (dataframe[:,1], dataframe[:,2]) will be considered when applying the function.\n",
    "    :return: numpy array contain the original features and the new created terms.\n",
    "    the terms from the second nonlinearity type (i.e. x1*x2, x1*x3,... etc)\n",
    "    \"\"\"\n",
    "    # consider only the required features when applying the function\n",
    "    if len(features_numbers_list) == 0:\n",
    "        features_numbers_list = list(range(numpy_array.shape[1]))\n",
    "    # initiate the list that contains the shapes which used to combine the features e.g. x1*x2\n",
    "    terms_shape_list = []\n",
    "    # applying the first nonlinearity which means x**degree e.g. x**2, x**3 and so on.\n",
    "    if map_degree > 1:\n",
    "        for degree_i in range(2, map_degree + 1):\n",
    "            # appending the features to the original array\n",
    "            numpy_array = np.concatenate((numpy_array, numpy_array[:, features_numbers_list] ** degree_i), axis=1)\n",
    "    # apply the second nonlinearity type which means introducing the dependency relationship like x1*x2\n",
    "    if terms_mix_degree > 1:\n",
    "        for mix_degree_i in range(2, terms_mix_degree + 1):\n",
    "            if map_degree > 1:\n",
    "                # in this case we don't miss terms like x2*x1**2 (x2*x1^2)\n",
    "                mapping_shape = list(it.combinations_with_replacement(range(features_numbers_list[0],\n",
    "                                                                            features_numbers_list[-1] + 1),\n",
    "                                                                      mix_degree_i))\n",
    "            else:\n",
    "                # we don't include the first type of nonlinearity like x1**2 (x1^2)\n",
    "                mapping_shape = list(\n",
    "                    it.combinations(range(features_numbers_list[0], features_numbers_list[-1] + 1), mix_degree_i))\n",
    "            for mapping_shape_i in mapping_shape:\n",
    "                if len(set(mapping_shape_i)) > 1:\n",
    "                    # initiate the term that should be calculated\n",
    "                    term_i = np.ones((len(numpy_array), 1))\n",
    "                    for feature_i in mapping_shape_i:\n",
    "                        # x1*x2*x3...\n",
    "                        term_i[:, 0] = np.multiply(term_i[:, 0], numpy_array[:, feature_i])\n",
    "                    # appending the features to the original array\n",
    "                    numpy_array = np.append(numpy_array.T, term_i.reshape(1, -1), axis=0).T\n",
    "                    # store the terms for the investigation\n",
    "                    terms_shape_list.append(mapping_shape_i)\n",
    "    return numpy_array, terms_shape_list\n",
    "\n",
    "\n",
    "def apply_mapping_features(dataframes_list, map_degree, terms_mix_degree, features_numbers_list):\n",
    "    \"\"\"\n",
    "    Appying the features_mapping function\n",
    "    :param dataframes_list: a list of pandas dataframe. e.g. [train, test]\n",
    "    :param map_degree: the nonlinearity degree. For example map_degree = 2 --> x and x^2 will be considered. If\n",
    "     map_degree = 3 --> x, x^2 and x^3 will be considered. If 0 is passed, this type of nonlinearity will be not\n",
    "     considered\n",
    "    :param terms_mix_degree: the nonlinearity degree. For example map_degree = 2 --> x and x^2 will be considered. If\n",
    "     map_degree = 3 --> x, x^2 and x^3 will be considered. If 0 is passed, this type of nonlinearity will be not\n",
    "     considered\n",
    "    :param features_numbers_list: list of integers that represents the features that should be considered by applying\n",
    "    this function.\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    if map_degree > 0 and terms_mix_degree > 1:\n",
    "        print(\"applying features mapping --> map_degree = {}, terms_mix_degree = {},\"\n",
    "              \" features_numbers_list = {}\".format(map_degree, terms_mix_degree, features_numbers_list))\n",
    "        mapped_dataframes_list = []\n",
    "\n",
    "        # applying the mapping features function to each dataframe inside the list\n",
    "        for dataset in dataframes_list:\n",
    "            mapped_dataset, _ = features_mapping(dataset.values, map_degree=map_degree,\n",
    "                                                 terms_mix_degree=terms_mix_degree,\n",
    "                                                 features_numbers_list=features_numbers_list)\n",
    "\n",
    "            # Prepare the results as dataframes and give names to the columns\n",
    "            mapped_dataframe = pd.DataFrame(mapped_dataset)\n",
    "            mapped_dataframe.columns = [\"col_{}\".format(x) for x in range(mapped_dataset.shape[1])]\n",
    "\n",
    "            # store the results\n",
    "            mapped_dataframes_list.append(mapped_dataframe)\n",
    "\n",
    "        return mapped_dataframes_list\n",
    "    else:\n",
    "        return dataframes_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "applying features mapping --> map_degree = 3, terms_mix_degree = 2, features_numbers_list = []\n"
     ]
    }
   ],
   "source": [
    "import itertools as it\n",
    "\n",
    "map_degree = 3\n",
    "terms_mix_degree = 2\n",
    "features_numbers_list = []\n",
    "\n",
    "datasets_list = [train_dataframe[numerical]]\n",
    "mapped_features_datasets = apply_mapping_features(datasets_list,\n",
    "                                                  map_degree,\n",
    "                                                  terms_mix_degree,\n",
    "                                                  features_numbers_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>col_0</th>\n",
       "      <th>col_1</th>\n",
       "      <th>col_2</th>\n",
       "      <th>col_3</th>\n",
       "      <th>col_4</th>\n",
       "      <th>col_5</th>\n",
       "      <th>col_6</th>\n",
       "      <th>col_7</th>\n",
       "      <th>col_8</th>\n",
       "      <th>col_9</th>\n",
       "      <th>...</th>\n",
       "      <th>col_197</th>\n",
       "      <th>col_198</th>\n",
       "      <th>col_199</th>\n",
       "      <th>col_200</th>\n",
       "      <th>col_201</th>\n",
       "      <th>col_202</th>\n",
       "      <th>col_203</th>\n",
       "      <th>col_204</th>\n",
       "      <th>col_205</th>\n",
       "      <th>col_206</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.208034</td>\n",
       "      <td>-0.207142</td>\n",
       "      <td>1.050994</td>\n",
       "      <td>0.878668</td>\n",
       "      <td>0.510015</td>\n",
       "      <td>0.575425</td>\n",
       "      <td>-0.288653</td>\n",
       "      <td>-0.944591</td>\n",
       "      <td>-0.459303</td>\n",
       "      <td>-0.793434</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.264014</td>\n",
       "      <td>0.075993</td>\n",
       "      <td>-0.126123</td>\n",
       "      <td>-0.094843</td>\n",
       "      <td>-0.162848</td>\n",
       "      <td>0.270276</td>\n",
       "      <td>0.203244</td>\n",
       "      <td>-0.077795</td>\n",
       "      <td>-0.058501</td>\n",
       "      <td>0.097093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.409895</td>\n",
       "      <td>-0.091886</td>\n",
       "      <td>0.156734</td>\n",
       "      <td>-0.429577</td>\n",
       "      <td>-0.572835</td>\n",
       "      <td>1.171992</td>\n",
       "      <td>-0.288653</td>\n",
       "      <td>-0.641228</td>\n",
       "      <td>0.466465</td>\n",
       "      <td>0.257140</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.098760</td>\n",
       "      <td>0.042784</td>\n",
       "      <td>0.021822</td>\n",
       "      <td>0.016410</td>\n",
       "      <td>-1.145627</td>\n",
       "      <td>-0.584332</td>\n",
       "      <td>-0.439411</td>\n",
       "      <td>0.253138</td>\n",
       "      <td>0.190357</td>\n",
       "      <td>0.097093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.084449</td>\n",
       "      <td>0.073480</td>\n",
       "      <td>0.984752</td>\n",
       "      <td>0.830215</td>\n",
       "      <td>0.322174</td>\n",
       "      <td>0.092907</td>\n",
       "      <td>-0.288653</td>\n",
       "      <td>-0.301643</td>\n",
       "      <td>-0.313369</td>\n",
       "      <td>-0.627826</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.475169</td>\n",
       "      <td>-0.044449</td>\n",
       "      <td>-0.226995</td>\n",
       "      <td>-0.170698</td>\n",
       "      <td>0.052924</td>\n",
       "      <td>0.270276</td>\n",
       "      <td>0.203244</td>\n",
       "      <td>0.025283</td>\n",
       "      <td>0.019012</td>\n",
       "      <td>0.097093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.414011</td>\n",
       "      <td>-0.096897</td>\n",
       "      <td>-1.863632</td>\n",
       "      <td>-0.720298</td>\n",
       "      <td>-0.572835</td>\n",
       "      <td>-0.499274</td>\n",
       "      <td>-0.288653</td>\n",
       "      <td>-0.061670</td>\n",
       "      <td>-0.687324</td>\n",
       "      <td>-0.521734</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.594824</td>\n",
       "      <td>-0.139220</td>\n",
       "      <td>3.236385</td>\n",
       "      <td>-0.213682</td>\n",
       "      <td>0.132419</td>\n",
       "      <td>-3.078297</td>\n",
       "      <td>0.203244</td>\n",
       "      <td>-0.720482</td>\n",
       "      <td>0.047570</td>\n",
       "      <td>-1.105834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.574676</td>\n",
       "      <td>0.375148</td>\n",
       "      <td>0.951632</td>\n",
       "      <td>0.733308</td>\n",
       "      <td>1.360826</td>\n",
       "      <td>0.463568</td>\n",
       "      <td>-0.288653</td>\n",
       "      <td>-0.174865</td>\n",
       "      <td>0.199680</td>\n",
       "      <td>-0.045611</td>\n",
       "      <td>...</td>\n",
       "      <td>1.325153</td>\n",
       "      <td>0.957538</td>\n",
       "      <td>-0.610308</td>\n",
       "      <td>-0.458945</td>\n",
       "      <td>0.439844</td>\n",
       "      <td>-0.280344</td>\n",
       "      <td>-0.210816</td>\n",
       "      <td>-0.202573</td>\n",
       "      <td>-0.152333</td>\n",
       "      <td>0.097093</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  207 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      col_0     col_1     col_2     col_3     col_4     col_5     col_6  \\\n",
       "0 -0.208034 -0.207142  1.050994  0.878668  0.510015  0.575425 -0.288653   \n",
       "1  0.409895 -0.091886  0.156734 -0.429577 -0.572835  1.171992 -0.288653   \n",
       "2 -0.084449  0.073480  0.984752  0.830215  0.322174  0.092907 -0.288653   \n",
       "3 -0.414011 -0.096897 -1.863632 -0.720298 -0.572835 -0.499274 -0.288653   \n",
       "4  0.574676  0.375148  0.951632  0.733308  1.360826  0.463568 -0.288653   \n",
       "\n",
       "      col_7     col_8     col_9    ...      col_197   col_198   col_199  \\\n",
       "0 -0.944591 -0.459303 -0.793434    ...    -0.264014  0.075993 -0.126123   \n",
       "1 -0.641228  0.466465  0.257140    ...    -0.098760  0.042784  0.021822   \n",
       "2 -0.301643 -0.313369 -0.627826    ...    -0.475169 -0.044449 -0.226995   \n",
       "3 -0.061670 -0.687324 -0.521734    ...    -0.594824 -0.139220  3.236385   \n",
       "4 -0.174865  0.199680 -0.045611    ...     1.325153  0.957538 -0.610308   \n",
       "\n",
       "    col_200   col_201   col_202   col_203   col_204   col_205   col_206  \n",
       "0 -0.094843 -0.162848  0.270276  0.203244 -0.077795 -0.058501  0.097093  \n",
       "1  0.016410 -1.145627 -0.584332 -0.439411  0.253138  0.190357  0.097093  \n",
       "2 -0.170698  0.052924  0.270276  0.203244  0.025283  0.019012  0.097093  \n",
       "3 -0.213682  0.132419 -3.078297  0.203244 -0.720482  0.047570 -1.105834  \n",
       "4 -0.458945  0.439844 -0.280344 -0.210816 -0.202573 -0.152333  0.097093  \n",
       "\n",
       "[5 rows x 207 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapped_features_datasets[0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of features before feature selection (1460, 225)\n",
      "size of features after feature selection (1460, 225)\n",
      "alpha = 1 R2 = 72.981\n",
      "alpha = 2 R2 = 74.556\n",
      "alpha = 3 R2 = 75.368\n",
      "alpha = 4 R2 = 76.058\n",
      "alpha = 5 R2 = 76.687\n",
      "alpha = 6 R2 = 77.266\n",
      "alpha = 7 R2 = 77.798\n",
      "alpha = 8 R2 = 78.288\n",
      "alpha = 9 R2 = 78.738\n",
      "alpha = 10 R2 = 79.153\n",
      "alpha = 11 R2 = 79.537\n",
      "alpha = 12 R2 = 79.892\n",
      "alpha = 13 R2 = 80.223\n",
      "alpha = 14 R2 = 80.53\n",
      "alpha = 15 R2 = 80.817\n",
      "alpha = 16 R2 = 81.085\n",
      "alpha = 17 R2 = 81.336\n",
      "alpha = 18 R2 = 81.572\n",
      "alpha = 19 R2 = 81.794\n",
      "alpha = 20 R2 = 82.003\n",
      "alpha = 21 R2 = 82.2\n",
      "alpha = 22 R2 = 82.386\n",
      "alpha = 23 R2 = 82.563\n",
      "alpha = 24 R2 = 82.73\n",
      "alpha = 25 R2 = 82.889\n",
      "alpha = 26 R2 = 83.04\n",
      "alpha = 27 R2 = 83.184\n",
      "alpha = 28 R2 = 83.32\n",
      "alpha = 29 R2 = 83.451\n",
      "alpha = 30 R2 = 83.576\n",
      "alpha = 31 R2 = 83.695\n",
      "alpha = 32 R2 = 83.809\n",
      "alpha = 33 R2 = 83.918\n",
      "alpha = 34 R2 = 84.023\n",
      "alpha = 35 R2 = 84.123\n",
      "alpha = 36 R2 = 84.219\n",
      "alpha = 37 R2 = 84.312\n",
      "alpha = 38 R2 = 84.401\n",
      "alpha = 39 R2 = 84.486\n",
      "alpha = 40 R2 = 84.569\n",
      "alpha = 41 R2 = 84.648\n",
      "alpha = 42 R2 = 84.724\n",
      "alpha = 43 R2 = 84.798\n",
      "alpha = 44 R2 = 84.869\n",
      "alpha = 45 R2 = 84.938\n",
      "alpha = 46 R2 = 85.004\n",
      "alpha = 47 R2 = 85.069\n",
      "alpha = 48 R2 = 85.131\n",
      "alpha = 49 R2 = 85.191\n",
      "alpha = 50 R2 = 85.249\n",
      "alpha = 51 R2 = 85.305\n",
      "alpha = 52 R2 = 85.36\n",
      "alpha = 53 R2 = 85.413\n",
      "alpha = 54 R2 = 85.464\n",
      "alpha = 55 R2 = 85.514\n",
      "alpha = 56 R2 = 85.562\n",
      "alpha = 57 R2 = 85.609\n",
      "alpha = 58 R2 = 85.654\n",
      "alpha = 59 R2 = 85.699\n",
      "alpha = 60 R2 = 85.742\n",
      "alpha = 61 R2 = 85.783\n",
      "alpha = 62 R2 = 85.824\n",
      "alpha = 63 R2 = 85.864\n",
      "alpha = 64 R2 = 85.902\n",
      "alpha = 65 R2 = 85.939\n",
      "alpha = 66 R2 = 85.976\n",
      "alpha = 67 R2 = 86.011\n",
      "alpha = 68 R2 = 86.046\n",
      "alpha = 69 R2 = 86.08\n",
      "alpha = 70 R2 = 86.113\n",
      "alpha = 71 R2 = 86.145\n",
      "alpha = 72 R2 = 86.176\n",
      "alpha = 73 R2 = 86.206\n",
      "alpha = 74 R2 = 86.236\n",
      "alpha = 75 R2 = 86.265\n",
      "alpha = 76 R2 = 86.294\n",
      "alpha = 77 R2 = 86.321\n",
      "alpha = 78 R2 = 86.348\n",
      "alpha = 79 R2 = 86.375\n",
      "alpha = 80 R2 = 86.4\n",
      "alpha = 81 R2 = 86.426\n",
      "alpha = 82 R2 = 86.45\n",
      "alpha = 83 R2 = 86.474\n",
      "alpha = 84 R2 = 86.498\n",
      "alpha = 85 R2 = 86.521\n",
      "alpha = 86 R2 = 86.543\n",
      "alpha = 87 R2 = 86.565\n",
      "alpha = 88 R2 = 86.587\n",
      "alpha = 89 R2 = 86.608\n",
      "alpha = 90 R2 = 86.629\n",
      "alpha = 91 R2 = 86.649\n",
      "alpha = 92 R2 = 86.668\n",
      "alpha = 93 R2 = 86.688\n",
      "alpha = 94 R2 = 86.707\n",
      "alpha = 95 R2 = 86.725\n",
      "alpha = 96 R2 = 86.743\n",
      "alpha = 97 R2 = 86.761\n",
      "alpha = 98 R2 = 86.778\n",
      "alpha = 99 R2 = 86.796\n",
      "alpha = 100 R2 = 86.812\n",
      "alpha = 101 R2 = 86.829\n",
      "alpha = 102 R2 = 86.845\n",
      "alpha = 103 R2 = 86.86\n",
      "alpha = 104 R2 = 86.876\n",
      "alpha = 105 R2 = 86.891\n",
      "alpha = 106 R2 = 86.906\n",
      "alpha = 107 R2 = 86.92\n",
      "alpha = 108 R2 = 86.934\n",
      "alpha = 109 R2 = 86.948\n",
      "alpha = 110 R2 = 86.962\n",
      "alpha = 111 R2 = 86.976\n",
      "alpha = 112 R2 = 86.989\n",
      "alpha = 113 R2 = 87.002\n",
      "alpha = 114 R2 = 87.014\n",
      "alpha = 115 R2 = 87.027\n",
      "alpha = 116 R2 = 87.039\n",
      "alpha = 117 R2 = 87.051\n",
      "alpha = 118 R2 = 87.063\n",
      "alpha = 119 R2 = 87.074\n",
      "alpha = 120 R2 = 87.085\n",
      "alpha = 121 R2 = 87.096\n",
      "alpha = 122 R2 = 87.107\n",
      "alpha = 123 R2 = 87.118\n",
      "alpha = 124 R2 = 87.129\n",
      "alpha = 125 R2 = 87.139\n",
      "alpha = 126 R2 = 87.149\n",
      "alpha = 127 R2 = 87.159\n",
      "alpha = 128 R2 = 87.169\n",
      "alpha = 129 R2 = 87.178\n",
      "alpha = 130 R2 = 87.188\n",
      "alpha = 131 R2 = 87.197\n",
      "alpha = 132 R2 = 87.206\n",
      "alpha = 133 R2 = 87.215\n",
      "alpha = 134 R2 = 87.223\n",
      "alpha = 135 R2 = 87.232\n",
      "alpha = 136 R2 = 87.24\n",
      "alpha = 137 R2 = 87.249\n",
      "alpha = 138 R2 = 87.257\n",
      "alpha = 139 R2 = 87.265\n",
      "alpha = 140 R2 = 87.272\n",
      "alpha = 141 R2 = 87.28\n",
      "alpha = 142 R2 = 87.288\n",
      "alpha = 143 R2 = 87.295\n",
      "alpha = 144 R2 = 87.302\n",
      "alpha = 145 R2 = 87.309\n",
      "alpha = 146 R2 = 87.316\n",
      "alpha = 147 R2 = 87.323\n",
      "alpha = 148 R2 = 87.33\n",
      "alpha = 149 R2 = 87.337\n",
      "alpha = 150 R2 = 87.343\n",
      "alpha = 151 R2 = 87.349\n",
      "alpha = 152 R2 = 87.356\n",
      "alpha = 153 R2 = 87.362\n",
      "alpha = 154 R2 = 87.368\n",
      "alpha = 155 R2 = 87.374\n",
      "alpha = 156 R2 = 87.38\n",
      "alpha = 157 R2 = 87.385\n",
      "alpha = 158 R2 = 87.391\n",
      "alpha = 159 R2 = 87.397\n",
      "alpha = 160 R2 = 87.402\n",
      "alpha = 161 R2 = 87.407\n",
      "alpha = 162 R2 = 87.412\n",
      "alpha = 163 R2 = 87.418\n",
      "alpha = 164 R2 = 87.423\n",
      "alpha = 165 R2 = 87.427\n",
      "alpha = 166 R2 = 87.432\n",
      "alpha = 167 R2 = 87.437\n",
      "alpha = 168 R2 = 87.442\n",
      "alpha = 169 R2 = 87.446\n",
      "alpha = 170 R2 = 87.451\n",
      "alpha = 171 R2 = 87.455\n",
      "alpha = 172 R2 = 87.459\n",
      "alpha = 173 R2 = 87.464\n",
      "alpha = 174 R2 = 87.468\n",
      "alpha = 175 R2 = 87.472\n",
      "alpha = 176 R2 = 87.476\n",
      "alpha = 177 R2 = 87.48\n",
      "alpha = 178 R2 = 87.484\n",
      "alpha = 179 R2 = 87.487\n",
      "alpha = 180 R2 = 87.491\n",
      "alpha = 181 R2 = 87.495\n",
      "alpha = 182 R2 = 87.498\n",
      "alpha = 183 R2 = 87.502\n",
      "alpha = 184 R2 = 87.505\n",
      "alpha = 185 R2 = 87.508\n",
      "alpha = 186 R2 = 87.511\n",
      "alpha = 187 R2 = 87.515\n",
      "alpha = 188 R2 = 87.518\n",
      "alpha = 189 R2 = 87.521\n",
      "alpha = 190 R2 = 87.524\n",
      "alpha = 191 R2 = 87.527\n",
      "alpha = 192 R2 = 87.53\n",
      "alpha = 193 R2 = 87.532\n",
      "alpha = 194 R2 = 87.535\n",
      "alpha = 195 R2 = 87.538\n",
      "alpha = 196 R2 = 87.54\n",
      "alpha = 197 R2 = 87.543\n",
      "alpha = 198 R2 = 87.545\n",
      "alpha = 199 R2 = 87.548\n",
      "alpha = 200 R2 = 87.55\n",
      "alpha = 201 R2 = 87.552\n",
      "alpha = 202 R2 = 87.555\n",
      "alpha = 203 R2 = 87.557\n",
      "alpha = 204 R2 = 87.559\n",
      "alpha = 205 R2 = 87.561\n",
      "alpha = 206 R2 = 87.563\n",
      "alpha = 207 R2 = 87.565\n",
      "alpha = 208 R2 = 87.567\n",
      "alpha = 209 R2 = 87.569\n",
      "alpha = 210 R2 = 87.571\n",
      "alpha = 211 R2 = 87.573\n",
      "alpha = 212 R2 = 87.575\n",
      "alpha = 213 R2 = 87.576\n",
      "alpha = 214 R2 = 87.578\n",
      "alpha = 215 R2 = 87.579\n",
      "alpha = 216 R2 = 87.581\n",
      "alpha = 217 R2 = 87.583\n",
      "alpha = 218 R2 = 87.584\n",
      "alpha = 219 R2 = 87.585\n",
      "alpha = 220 R2 = 87.587\n",
      "alpha = 221 R2 = 87.588\n",
      "alpha = 222 R2 = 87.589\n",
      "alpha = 223 R2 = 87.591\n",
      "alpha = 224 R2 = 87.592\n",
      "alpha = 225 R2 = 87.593\n",
      "alpha = 226 R2 = 87.594\n",
      "alpha = 227 R2 = 87.595\n",
      "alpha = 228 R2 = 87.596\n",
      "alpha = 229 R2 = 87.597\n",
      "alpha = 230 R2 = 87.598\n",
      "alpha = 231 R2 = 87.599\n",
      "alpha = 232 R2 = 87.6\n",
      "alpha = 233 R2 = 87.601\n",
      "alpha = 234 R2 = 87.602\n",
      "alpha = 235 R2 = 87.603\n",
      "alpha = 236 R2 = 87.603\n",
      "alpha = 237 R2 = 87.604\n",
      "alpha = 238 R2 = 87.605\n",
      "alpha = 239 R2 = 87.605\n",
      "alpha = 240 R2 = 87.606\n",
      "alpha = 241 R2 = 87.607\n",
      "alpha = 242 R2 = 87.607\n",
      "alpha = 243 R2 = 87.608\n",
      "alpha = 244 R2 = 87.608\n",
      "alpha = 245 R2 = 87.608\n",
      "alpha = 246 R2 = 87.609\n",
      "alpha = 247 R2 = 87.609\n",
      "alpha = 248 R2 = 87.61\n",
      "alpha = 249 R2 = 87.61\n",
      "alpha = 250 R2 = 87.61\n",
      "alpha = 251 R2 = 87.61\n",
      "alpha = 252 R2 = 87.611\n",
      "alpha = 253 R2 = 87.611\n",
      "alpha = 254 R2 = 87.611\n",
      "alpha = 255 R2 = 87.611\n",
      "alpha = 256 R2 = 87.611\n",
      "alpha = 257 R2 = 87.611\n",
      "alpha = 258 R2 = 87.611\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import KFold\n",
    "best_score = 0.0\n",
    "\n",
    "\n",
    "X_train_df = pd.concat([mapped_features_datasets[0],train_dataframe[categorical_columns]],axis=1)\n",
    "#X_train_df = mapped_features_datasets[0]\n",
    "X_train_df = standard_scale_nuermical_features(X_train_df)\n",
    "\n",
    "\n",
    "train_array = X_train_df\n",
    "print(\"size of features before feature selection\", train_array.shape)\n",
    "# apply feature selection\n",
    "train_array = feature_selection(train_array)\n",
    "print(\"size of features after feature selection\", train_array.shape)\n",
    "\n",
    "\n",
    "y_train = np.array(train_target)\n",
    "y_train = y_train.reshape(y_train.shape[0], 1)\n",
    "\n",
    "for regul in range(1,1000):\n",
    "    linear_regression_model = linear_model.Ridge(alpha=regul)\n",
    "\n",
    "    predictions = 0\n",
    "    n_fold = 5  # number of folds\n",
    "    kfold = KFold(n_splits=n_fold, shuffle=True, random_state=1)\n",
    "\n",
    "    fold_nr = 0  # counter for identifying models\n",
    "    r2_linear = 0\n",
    "\n",
    "    for train, test in kfold.split(train_array):\n",
    "        fold_nr += 1\n",
    "        #print(\"foldnr.\", fold_nr)\n",
    "        linear_regression_model.fit(train_array[train], y_train[train])\n",
    "\n",
    "        y_pred_linear = linear_regression_model.predict(train_array[test])\n",
    "\n",
    "        #print(\"Mean squared error linear: %.2f\"\n",
    "         #     % mean_squared_error(y_train[test], y_pred_linear))\n",
    "\n",
    "        #print('R2 linear: %.2f' % r2_score(y_train[test], y_pred_linear))\n",
    "\n",
    "        r2_linear += r2_score(y_train[test], y_pred_linear)\n",
    "\n",
    "    # mean R2\n",
    "    #print(r2_linear/n_fold)\n",
    "    if r2_linear/n_fold > best_score:\n",
    "        best_score = r2_linear/n_fold\n",
    "        print(f\"alpha = {regul}\", f\"R2 = {round(100*best_score,3)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "applying features mapping --> map_degree = 2, terms_mix_degree = 2, features_numbers_list = []\n"
     ]
    }
   ],
   "source": [
    "datasets_list = [train_dataframe_[numerical]]\n",
    "mapped_features_datasets_ = apply_mapping_features(datasets_list,\n",
    "                                                  map_degree,\n",
    "                                                  terms_mix_degree,\n",
    "                                                  features_numbers_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of features before feature selection (1460, 207)\n",
      "size of features after feature selection (1460, 207)\n",
      "alpha = 1 R2 = 84.506\n",
      "alpha = 2 R2 = 84.615\n",
      "alpha = 3 R2 = 84.741\n",
      "alpha = 4 R2 = 84.869\n",
      "alpha = 5 R2 = 84.995\n",
      "alpha = 6 R2 = 85.117\n",
      "alpha = 7 R2 = 85.235\n",
      "alpha = 8 R2 = 85.348\n",
      "alpha = 9 R2 = 85.455\n",
      "alpha = 10 R2 = 85.558\n",
      "alpha = 11 R2 = 85.655\n",
      "alpha = 12 R2 = 85.748\n",
      "alpha = 13 R2 = 85.837\n",
      "alpha = 14 R2 = 85.922\n",
      "alpha = 15 R2 = 86.003\n",
      "alpha = 16 R2 = 86.08\n",
      "alpha = 17 R2 = 86.153\n",
      "alpha = 18 R2 = 86.224\n",
      "alpha = 19 R2 = 86.291\n",
      "alpha = 20 R2 = 86.355\n",
      "alpha = 21 R2 = 86.417\n",
      "alpha = 22 R2 = 86.476\n",
      "alpha = 23 R2 = 86.532\n",
      "alpha = 24 R2 = 86.587\n",
      "alpha = 25 R2 = 86.639\n",
      "alpha = 26 R2 = 86.689\n",
      "alpha = 27 R2 = 86.737\n",
      "alpha = 28 R2 = 86.783\n",
      "alpha = 29 R2 = 86.828\n",
      "alpha = 30 R2 = 86.871\n",
      "alpha = 31 R2 = 86.912\n",
      "alpha = 32 R2 = 86.952\n",
      "alpha = 33 R2 = 86.99\n",
      "alpha = 34 R2 = 87.027\n",
      "alpha = 35 R2 = 87.063\n",
      "alpha = 36 R2 = 87.097\n",
      "alpha = 37 R2 = 87.13\n",
      "alpha = 38 R2 = 87.163\n",
      "alpha = 39 R2 = 87.194\n",
      "alpha = 40 R2 = 87.224\n",
      "alpha = 41 R2 = 87.253\n",
      "alpha = 42 R2 = 87.281\n",
      "alpha = 43 R2 = 87.308\n",
      "alpha = 44 R2 = 87.334\n",
      "alpha = 45 R2 = 87.36\n",
      "alpha = 46 R2 = 87.384\n",
      "alpha = 47 R2 = 87.408\n",
      "alpha = 48 R2 = 87.431\n",
      "alpha = 49 R2 = 87.454\n",
      "alpha = 50 R2 = 87.476\n",
      "alpha = 51 R2 = 87.497\n",
      "alpha = 52 R2 = 87.517\n",
      "alpha = 53 R2 = 87.537\n",
      "alpha = 54 R2 = 87.556\n",
      "alpha = 55 R2 = 87.575\n",
      "alpha = 56 R2 = 87.593\n",
      "alpha = 57 R2 = 87.611\n",
      "alpha = 58 R2 = 87.628\n",
      "alpha = 59 R2 = 87.645\n",
      "alpha = 60 R2 = 87.661\n",
      "alpha = 61 R2 = 87.676\n",
      "alpha = 62 R2 = 87.692\n",
      "alpha = 63 R2 = 87.707\n",
      "alpha = 64 R2 = 87.721\n",
      "alpha = 65 R2 = 87.735\n",
      "alpha = 66 R2 = 87.748\n",
      "alpha = 67 R2 = 87.762\n",
      "alpha = 68 R2 = 87.775\n",
      "alpha = 69 R2 = 87.787\n",
      "alpha = 70 R2 = 87.799\n",
      "alpha = 71 R2 = 87.811\n",
      "alpha = 72 R2 = 87.822\n",
      "alpha = 73 R2 = 87.834\n",
      "alpha = 74 R2 = 87.844\n",
      "alpha = 75 R2 = 87.855\n",
      "alpha = 76 R2 = 87.865\n",
      "alpha = 77 R2 = 87.875\n",
      "alpha = 78 R2 = 87.885\n",
      "alpha = 79 R2 = 87.894\n",
      "alpha = 80 R2 = 87.904\n",
      "alpha = 81 R2 = 87.913\n",
      "alpha = 82 R2 = 87.921\n",
      "alpha = 83 R2 = 87.93\n",
      "alpha = 84 R2 = 87.938\n",
      "alpha = 85 R2 = 87.946\n",
      "alpha = 86 R2 = 87.954\n",
      "alpha = 87 R2 = 87.961\n",
      "alpha = 88 R2 = 87.969\n",
      "alpha = 89 R2 = 87.976\n",
      "alpha = 90 R2 = 87.983\n",
      "alpha = 91 R2 = 87.99\n",
      "alpha = 92 R2 = 87.996\n",
      "alpha = 93 R2 = 88.003\n",
      "alpha = 94 R2 = 88.009\n",
      "alpha = 95 R2 = 88.015\n",
      "alpha = 96 R2 = 88.021\n",
      "alpha = 97 R2 = 88.026\n",
      "alpha = 98 R2 = 88.032\n",
      "alpha = 99 R2 = 88.037\n",
      "alpha = 100 R2 = 88.043\n",
      "alpha = 101 R2 = 88.048\n",
      "alpha = 102 R2 = 88.053\n",
      "alpha = 103 R2 = 88.057\n",
      "alpha = 104 R2 = 88.062\n",
      "alpha = 105 R2 = 88.066\n",
      "alpha = 106 R2 = 88.071\n",
      "alpha = 107 R2 = 88.075\n",
      "alpha = 108 R2 = 88.079\n",
      "alpha = 109 R2 = 88.083\n",
      "alpha = 110 R2 = 88.087\n",
      "alpha = 111 R2 = 88.091\n",
      "alpha = 112 R2 = 88.094\n",
      "alpha = 113 R2 = 88.098\n",
      "alpha = 114 R2 = 88.101\n",
      "alpha = 115 R2 = 88.104\n",
      "alpha = 116 R2 = 88.108\n",
      "alpha = 117 R2 = 88.111\n",
      "alpha = 118 R2 = 88.114\n",
      "alpha = 119 R2 = 88.116\n",
      "alpha = 120 R2 = 88.119\n",
      "alpha = 121 R2 = 88.122\n",
      "alpha = 122 R2 = 88.124\n",
      "alpha = 123 R2 = 88.127\n",
      "alpha = 124 R2 = 88.129\n",
      "alpha = 125 R2 = 88.131\n",
      "alpha = 126 R2 = 88.134\n",
      "alpha = 127 R2 = 88.136\n",
      "alpha = 128 R2 = 88.138\n",
      "alpha = 129 R2 = 88.14\n",
      "alpha = 130 R2 = 88.141\n",
      "alpha = 131 R2 = 88.143\n",
      "alpha = 132 R2 = 88.145\n",
      "alpha = 133 R2 = 88.146\n",
      "alpha = 134 R2 = 88.148\n",
      "alpha = 135 R2 = 88.149\n",
      "alpha = 136 R2 = 88.151\n",
      "alpha = 137 R2 = 88.152\n",
      "alpha = 138 R2 = 88.153\n",
      "alpha = 139 R2 = 88.154\n",
      "alpha = 140 R2 = 88.156\n",
      "alpha = 141 R2 = 88.157\n",
      "alpha = 142 R2 = 88.157\n",
      "alpha = 143 R2 = 88.158\n",
      "alpha = 144 R2 = 88.159\n",
      "alpha = 145 R2 = 88.16\n",
      "alpha = 146 R2 = 88.161\n",
      "alpha = 147 R2 = 88.161\n",
      "alpha = 148 R2 = 88.162\n",
      "alpha = 149 R2 = 88.162\n",
      "alpha = 150 R2 = 88.163\n",
      "alpha = 151 R2 = 88.163\n",
      "alpha = 152 R2 = 88.164\n",
      "alpha = 153 R2 = 88.164\n",
      "alpha = 154 R2 = 88.164\n",
      "alpha = 155 R2 = 88.164\n",
      "alpha = 156 R2 = 88.165\n",
      "alpha = 157 R2 = 88.165\n",
      "alpha = 158 R2 = 88.165\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import KFold\n",
    "best_score = 0.77\n",
    "\n",
    "\n",
    "X_train_df = pd.concat([mapped_features_datasets_[0],train_dataframe[categorical_columns]],axis=1)\n",
    "#X_train_df = mapped_features_datasets[0]\n",
    "X_train_df = standard_scale_nuermical_features(X_train_df)\n",
    "\n",
    "\n",
    "train_array = X_train_df\n",
    "print(\"size of features before feature selection\", train_array.shape)\n",
    "# apply feature selection\n",
    "train_array = feature_selection(train_array)\n",
    "print(\"size of features after feature selection\", train_array.shape)\n",
    "\n",
    "\n",
    "y_train = np.array(train_target)\n",
    "y_train = y_train.reshape(y_train.shape[0], 1)\n",
    "\n",
    "for regul in range(1,1000):\n",
    "    linear_regression_model = linear_model.Ridge(alpha=regul)\n",
    "\n",
    "    predictions = 0\n",
    "    n_fold = 5  # number of folds\n",
    "    kfold = KFold(n_splits=n_fold, shuffle=True, random_state=1)\n",
    "\n",
    "    fold_nr = 0  # counter for identifying models\n",
    "    r2_linear = 0\n",
    "\n",
    "    for train, test in kfold.split(train_array):\n",
    "        fold_nr += 1\n",
    "        #print(\"foldnr.\", fold_nr)\n",
    "        linear_regression_model.fit(train_array[train], y_train[train])\n",
    "\n",
    "        y_pred_linear = linear_regression_model.predict(train_array[test])\n",
    "\n",
    "        #print(\"Mean squared error linear: %.2f\"\n",
    "         #     % mean_squared_error(y_train[test], y_pred_linear))\n",
    "\n",
    "        #print('R2 linear: %.2f' % r2_score(y_train[test], y_pred_linear))\n",
    "\n",
    "        r2_linear += r2_score(y_train[test], y_pred_linear)\n",
    "\n",
    "    # mean R2\n",
    "    #print(r2_linear/n_fold)\n",
    "    if r2_linear/n_fold > best_score:\n",
    "        best_score = r2_linear/n_fold\n",
    "        print(f\"alpha = {regul}\", f\"R2 = {round(100*best_score,3)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
